<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>2. The Advanced Privacy Guide</title>
</head>
<body>
    <article>
        <h1 class="font-mono border-b border-shell-border pb-2 mb-6">
            <span class="text-gray-500">#</span> 2. The Advanced Privacy Guide
        </h1>

        <p class="text-xl text-shell-accent/90 leading-relaxed">
            Tactical digital defense for everyday users who refuse to hand control of their data to anyone else.
        </p>
        <p>
            This playbook speaks to journalists, Linux and BSD operators, advocates, and anyone facing adversaries that watch everything. It favors discipline over drama and assumes you already operate inside terminals, encrypted vaults, and compartmentalized workflows.
        </p>

        <h2>Operational Security Matrix (Quick Reference)</h2>
        <p>
            Use this matrix to quickly identify which security measures to prioritize based on your threat model. Match the threat you're facing with the corresponding defense strategy and immediate action items. Complexity indicates implementation difficulty, not importance.
        </p>
        <div style="overflow-x:auto; margin-bottom:2rem;">
            <table>
                <thead>
                    <tr>
                        <th>Security Domain</th>
                        <th>What You're Protecting Against</th>
                        <th>Defense Strategy</th>
                        <th>First Steps to Take</th>
                        <th>Difficulty</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>1. Threat Modeling</strong></td>
                        <td>Wasted effort on wrong threats, incomplete defenses</td>
                        <td>Understand your actual risks before deploying tools</td>
                        <td>List your assets, identify who wants them, assess impact of compromise</td>
                        <td>Low</td>
                    </tr>
                    <tr>
                        <td><strong>2. Anti-Doxing</strong></td>
                        <td>Identity exposure through writing style, leaked personal info, OSINT</td>
                        <td>Break linkability between identities and obscure patterns</td>
                        <td>Use OFFLINE(!) LLM to rewrite text, vary syntax, scrub translation artifacts</td>
                        <td>High</td>
                    </tr>
                    <tr>
                        <td><strong>3. Hardware Security</strong></td>
                        <td>Evil Maid attacks, physical tampering, firmware backdoors</td>
                        <td>Verify boot chain integrity and prevent unauthorized access</td>
                        <td>Enable Secure Boot, install Heads firmware, configure usbguard</td>
                        <td>High</td>
                    </tr>
                    <tr>
                        <td><strong>4. Identity Separation</strong></td>
                        <td>Cross-context tracking, profile correlation, persona linkage</td>
                        <td>Keep different online identities completely isolated</td>
                        <td>Use separate VMs per identity, Tor Browser, Qubes OS compartments</td>
                        <td>Medium</td>
                    </tr>
                    <tr>
                        <td><strong>5. Authentication</strong></td>
                        <td>Phishing, credential stuffing, brute force, SIM swap attacks</td>
                        <td>Strong unique passwords plus hardware-based second factor</td>
                        <td>Get YubiKey/Nitrokey, generate Diceware passphrases, use offline password manager</td>
                        <td>Low</td>
                    </tr>
                    <tr>
                        <td><strong>6. Secure Communication</strong></td>
                        <td>Message interception, metadata leaks, man-in-the-middle</td>
                        <td>End-to-end encryption with verified contacts</td>
                        <td>Install Signal or Session, verify safety numbers, never use SMS/email for sensitive content</td>
                        <td>Low</td>
                    </tr>
                    <tr>
                        <td><strong>7. Metadata Removal</strong></td>
                        <td>Location tracking, device fingerprints, hidden file data</td>
                        <td>Strip identifying information from all shared files</td>
                        <td>Install ExifTool or MAT2, scrub files before upload, remove EXIF from photos</td>
                        <td>Medium</td>
                    </tr>
                    <tr>
                        <td><strong>8. Data Encryption</strong></td>
                        <td>Device theft, border searches, law enforcement seizure</td>
                        <td>Encrypt all data at rest with strong passphrases</td>
                        <td>Enable LUKS2 full disk encryption, create VeraCrypt containers, use GPG for sensitive files</td>
                        <td>Medium</td>
                    </tr>
                    <tr>
                        <td><strong>9. Network Privacy</strong></td>
                        <td>ISP surveillance, DNS leaks, traffic analysis, correlation attacks</td>
                        <td>Control DNS queries and mask network traffic patterns</td>
                        <td>Deploy Pi-hole + Unbound recursive DNS, install OpenSnitch firewall, route through Tor when needed</td>
                        <td>Medium</td>
                    </tr>
                    <tr>
                        <td><strong>10. Virtualization</strong></td>
                        <td>Malware persistence, untrusted software, exploit attempts</td>
                        <td>Isolate risky activities in disposable sandboxes</td>
                        <td>Create disposable VMs for testing, take snapshots before risky operations, use Qubes OS</td>
                        <td>Medium</td>
                    </tr>
                    <tr>
                        <td><strong>11. Physical Security</strong></td>
                        <td>Tampered hardware, cold boot attacks, unattended device access</td>
                        <td>Detect tampering and prevent memory extraction</td>
                        <td>Apply glitter nail polish to screws, store devices in Faraday bags, always full shutdown (never sleep)</td>
                        <td>Low</td>
                    </tr>
                    <tr>
                        <td><strong>12. Financial Privacy</strong></td>
                        <td>Purchase tracking, transaction surveillance, payment correlation</td>
                        <td>Break the link between payments and identity</td>
                        <td>Use Monero for online purchases, pay cash when possible, randomize ATM withdrawal timing/location</td>
                        <td>Medium</td>
                    </tr>
                    <tr>
                        <td><strong>13. Supply Chain</strong></td>
                        <td>Trojanized updates, malicious dependencies, backdoored software</td>
                        <td>Verify authenticity before installing anything</td>
                        <td>Check GPG signatures on downloads, verify SHA256 checksums, use reproducible builds when available</td>
                        <td>Medium</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <h2>1. Understanding Your Risks (Threat Modeling)</h2>
        <p>
            Security is never one size fits all. A journalist in a conflict zone, an advocate coordinating legal support, and a developer dodging ad trackers all face different threats. Define your attack surface, map the likely adversaries, and document the impact of compromise before you deploy a single tool.
        </p>
        
        <p>
            <strong>Why This Matters:</strong> Without a threat model, you waste resources defending against unlikely threats while ignoring realistic ones. A threat model transforms abstract paranoia into concrete, actionable priorities. It answers "What am I protecting?", "Who wants it?", and "What happens if they succeed?"
        </p>

        <h3>Threat Modeling Workflow</h3>
        <ol>
            <li>
                <strong>List your assets:</strong> Catalog data stores, credentials, contacts, and physical hardware. The EFF Surveillance Self-Defense project recommends noting location, who currently has access, and the safeguards already in place.
                <p><em>Security Impact:</em> You cannot protect what you do not inventory. A forgotten backup drive or cloud account becomes the weakest link. Document everything: laptops, phones, USB drives, cloud storage, email accounts, messaging apps, password managers, and backup locations.</p>
            </li>
            <li>
                <strong>Enumerate adversaries:</strong> Rank likely actors by capability and intent. Corporate data brokers correlate browsing metadata. Nation-state programs combine data retention mandates with packet capture. Local threats include stalkers, hostile coworkers, or corrupt officials.
                <p><em>Security Impact:</em> Different adversaries require different defenses. A stalker cannot subpoena your ISP, but they can phish you. A nation-state can compel service providers to hand over data, but they rarely target individuals unless you are high-value. Understanding capability helps you allocate defenses appropriately.</p>
            </li>
            <li>
                <strong>Estimate impact:</strong> Document best and worst outcomes if an asset leaks. Tie each outcome to legal, reputational, operational, and physical consequences.
                <p><em>Security Impact:</em> Impact assessment determines priority. Losing your grocery list is inconvenient. Losing source contact information can be fatal. Rank assets by consequence: life-threatening, career-ending, legally actionable, embarrassing, or trivial.</p>
            </li>
            <li>
                <strong>Prioritize controls:</strong> Weigh the probability of each event against the cost of mitigation. If a threat is catastrophic with a realistic likelihood, fund the defense even if it is tedious.
                <p><em>Security Impact:</em> Security is about managing finite resources. You cannot defend everything perfectly. Focus effort where risk is highest: high-probability, high-impact scenarios get top priority. Low-probability, low-impact threats can wait.</p>
            </li>
            <li>
                <strong>Review quarterly:</strong> Calendar a threat modeling retro so you can update adversary assumptions, technology stack, and travel patterns.
                <p><em>Security Impact:</em> Threat landscapes evolve. A new job, relationship, or political climate changes your risk profile. Quarterly reviews ensure your defenses stay aligned with current reality rather than stale assumptions.</p>
            </li>
        </ol>

        <h3>Corporate Data Mining</h3>
        <ul>
            <li><strong>The Threat:</strong> Platforms build shadow profiles even when you never log in. IP addresses, browser fingerprints, and purchase histories merge into predictive dossiers.</li>
            <li><strong>Defense Strategy:</strong> Obfuscate the signals. Block third-party scripts with uBlock Origin in hard mode or LibreWolf. Rotate VPN exit regions, randomize browser agents, and refuse loyalty schemes that feed retail telemetry.</li>
        </ul>
        
        <p><strong>Why This Matters:</strong> Data brokers sell your profile to insurers who raise rates, employers who deny jobs, and advertisers who manipulate behavior. Even without an account, trackers follow you across sites through pixels, cookies, and fingerprints. Your browsing history reveals health conditions, financial status, political views, and personal relationships.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Install uBlock Origin and set to hard mode
# Firefox: about:addons → Search "uBlock Origin" → Install
# Enable "I am an advanced user" in settings
# Default-deny all third-party scripts and frames
# Why: Blocks third-party trackers, ads, and fingerprinting scripts
# Use when: You want maximum privacy without switching browsers

# Or use LibreWolf (hardened Firefox fork)
# Debian/Ubuntu:

# Install prerequisites for repository management
# wget = download files from web
# gnupg = GPG signature verification
sudo apt install -y wget gnupg
# Expected output: Package installation messages
# Why: Need tools to securely add LibreWolf repository

# Download and install LibreWolf signing key
# -qO- = quiet mode, output to stdout
# gpg --dearmor = convert ASCII key to binary format
# -o = output file location
wget -qO- https://deb.librewolf.net/keyring.gpg | sudo gpg --dearmor -o /usr/share/keyrings/librewolf.gpg
# Expected output: GPG key saved to keyrings directory
# Why: Verify package authenticity (prevent MITM attacks)
# Security: Without key verification, attacker could serve malicious packages

# Add LibreWolf repository to apt sources
# $(lsb_release -sc) = your Ubuntu/Debian codename (jammy, bookworm, etc.)
# signed-by = only trust packages signed with this specific key
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/librewolf.gpg] https://deb.librewolf.net $(lsb_release -sc) main" | sudo tee /etc/apt/sources.list.d/librewolf.list
# Expected output: Repository line added to /etc/apt/sources.list.d/
# Why: Tell apt where to download LibreWolf packages from

# Update package lists and install LibreWolf
# apt update = refresh package index from all repositories
# && = only run second command if first succeeds
# -y = automatically answer yes to prompts
sudo apt update && sudo apt install librewolf -y
# Expected output: Package database updated, LibreWolf installed
# Why: LibreWolf is Firefox with privacy-hardening by default
# Security: Disables telemetry, enables tracking protection, removes Mozilla spyware
# Use when: You want privacy-respecting browser without manual configuration</code></pre>

        <h3>State Surveillance</h3>
        <ul>
            <li><strong>The Threat:</strong> Intelligence agencies run on a collect-it-all doctrine. Metadata about who you speak with and when often exposes more than the message content.</li>
            <li><strong>Defense Strategy:</strong> Minimize emissions. Use end-to-end encryption, TLS 1.3, and anonymity systems such as Tor or Snowflake bridges. Harden mobile devices by disabling Wi-Fi and Bluetooth scanning, which leak probe requests even when not connected.</li>
        </ul>
        
        <p><strong>Why This Matters:</strong> State actors have legal authority to compel service providers, intercept traffic at internet exchange points, and deploy implants via supply chain. They store encrypted data for future decryption when quantum computing matures. Metadata analysis reveals your social network, daily routine, location history, and communication patterns: often more valuable than content.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Disable Wi-Fi/Bluetooth scanning on Android
# Settings → Location → Wi-Fi scanning → OFF
# Settings → Location → Bluetooth scanning → OFF
# Why: Phones scan for WiFi/BT even when "off", leaking location
# Security: Probe requests contain MAC address, reveal your location history
# Use when: Traveling through hostile areas or avoiding tracking

# Install Tor Browser
# Arch Linux:

# Install Tor daemon and browser launcher
# tor = background service that maintains Tor circuit
# torbrowser-launcher = wrapper that downloads and manages Tor Browser
sudo pacman -S tor torbrowser-launcher
# Expected output: Packages installed from Arch repositories
# Why: pacman is Arch's package manager

# Launch Tor Browser (first run downloads browser bundle)
torbrowser-launcher
# Expected output: Downloads Tor Browser if needed, then launches
# Why: Tor Browser routes all traffic through 3 random relays
# Security: Your ISP sees Tor connection but not destination
# Security: Destination sees Tor exit node IP, not your real IP
# Use when: Need anonymity (whistleblowing, circumventing censorship)

# Or use Snowflake bridge for censored networks
# Tor Browser → Settings → Tor → Bridges → Request a bridge → snowflake
# Why: Standard Tor connections are blocked in China, Iran, etc.
# Security: Snowflake uses ephemeral proxies provided by volunteers
# Use when: Direct Tor connections are censored in your region

# Verify TLS 1.3 support
# s_client = SSL/TLS client for testing
# -connect = server:port to test
# -tls1_3 = request TLS version 1.3
# 2>&1 = redirect errors to stdout
# grep "Protocol" = filter for protocol version line
openssl s_client -connect example.com:443 -tls1_3 2>&1 | grep "Protocol"
# Expected output: Protocol  : TLSv1.3
# Why: TLS 1.3 is faster and more secure than 1.2
# Security: TLS 1.3 removes weak ciphers, encrypts more handshake data
# Use when: Verifying a server supports modern encryption standards</code></pre>

        <h3>Targeted Harassment and Doxing</h3>
        <ul>
            <li><strong>The Threat:</strong> Harassers stitch together fragments from legacy accounts, reused usernames, and photographs to identify you or your family.</li>
            <li><strong>Defense Strategy:</strong> Build alias personas with distinct password vaults, email forwarding rules, and payment sources. Purge dormant posts with tools such as Semiphemeral and request data deletion under privacy law where available.</li>
        </ul>
        
        <p><strong>Why This Matters:</strong> Doxing rarely requires elite hacking skills: most attacks succeed through patient OSINT. Reused usernames across platforms, metadata in photos, background details in videos, and writing style analysis can all link pseudonymous accounts to real identities. Once doxed, physical addresses, employer information, and family details become public, enabling harassment, swatting, or worse.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Check username exposure with Sherlock
# Searches 300+ social media sites for username matches
# pip3 = Python 3 package installer
# install = download and install package from PyPI
pip3 install sherlock-project
# Expected output: Package and dependencies installed
# Why: Need to check if your username is exposed across platforms

# Run Sherlock scan
# Searches for your_username_here across all supported sites
sherlock your_username_here
# Expected output: List of sites where username exists with URLs
# Why: Reveals cross-platform username reuse (doxing vulnerability)
# Security: Each matching site is correlation point linking your accounts
# Use when: Checking new username before adoption or auditing existing aliases

# Alternative: Maigret (more comprehensive)
# Checks 2500+ sites vs Sherlock's 300+
pip3 install maigret
# Expected output: Package installed

# Run Maigret scan (slower but more thorough)
maigret your_username_here
# Expected output: Comprehensive list of username matches with metadata
# Why: More sites scanned = better coverage of username exposure
# Use when: Doing deep OSINT on username before committing to alias

# Purge old Reddit/Twitter posts with Semiphemeral
# Automatically deletes old social media posts based on rules
# (keep recent posts, delete old ones to reduce attack surface)
pip3 install semiphemeral
# Expected output: Semiphemeral installed
# Follow setup at: https://github.com/micahflee/semiphemeral
# Why: Old posts accumulate PII and can be used for doxing
# Security: Reduces historical data available for correlation attacks
# Use when: Maintaining active social media while limiting exposure

# Check if your email leaked in breaches
# Visit: https://haveibeenpwned.com/
# Why: Data breaches expose emails, passwords, personal info
# Security: If email found, assume password compromised
# Use when: Checking if you need to change passwords/enable 2FA

# Request data deletion under GDPR/CCPA
# Template email:
# Subject: GDPR Article 17 Right to Erasure Request
# Body: I request immediate deletion of all my personal data 
# under GDPR Article 17. My account email: example@domain.com
# Why: EU GDPR and California CCPA give right to deletion
# Security: Forces companies to purge your data from their systems
# Use when: Retiring identity or reducing data broker exposure
# Note: Must prove identity, response required within 30 days</code></pre>

        <h2>2. Preventing Doxing and Linguistic Fingerprinting</h2>
        <p>
            Doxing seldom requires deep technical skill. It thrives on connecting thousands of tiny clues that you leave behind. Stylometry, audio metadata, and behavioral patterns all betray identity.
        </p>
        
        <p><strong>Why This Matters:</strong> Stylometry: the statistical analysis of writing style: can link anonymous posts to known authors with high accuracy. Researchers have demonstrated 80-90% accuracy in authorship attribution using sentence length, vocabulary richness, punctuation patterns, and grammatical quirks. Even "anonymous" posts on Reddit, forums, or blogs can be traced back to you if your writing style is distinctive and consistent across platforms.</p>

        <h3>Stylometry Countermeasures</h3>
        <ul>
            <li>Draft sensitive posts in a text transformer that randomizes sentence structure and vocabulary, then review manually so meaning stays intact.</li>
            <li>Switch keyboard layouts or language settings to introduce consistent character usage noise that breaks signature matching.</li>
            <li>Maintain style guides for each persona. A change log helps you stay consistent with deliberate quirks while avoiding involuntary tells.</li>
        </ul>
        
        <p><strong>Security Impact:</strong> Your writing style is as unique as a fingerprint. Consistent use of certain phrases ("I reckon", "folks", "needless to say"), sentence length patterns, comma placement, and even typos create a signature. Academic studies show that machine learning can identify authors from samples as small as 500 words.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Use GPT/Claude locally to rewrite text with different style
# Install ollama for local LLM

# Download and install Ollama (local LLM runtime)
# -fsSL = fail silently, silent mode, follow redirects, output to stdout
# | sh = pipe download to shell for execution
curl -fsSL https://ollama.com/install.sh | sh
# Expected output: Ollama installed to /usr/local/bin/
# Why: Run AI models locally without sending data to cloud services
# Security: Text never leaves your machine (no OpenAI/Anthropic logging)
# Use when: Rewriting sensitive text that can't be shared with third parties

# Download Mistral 7B model (4.1GB, good balance of speed/quality)
# pull = download model from Ollama library
ollama pull mistral
# Expected output: Downloading model in chunks, progress bar
# Why: Mistral is open-source LLM capable of text rewriting
# Note: Requires ~8GB RAM, uses GPU if available

# Rewrite script example (save as rewrite.sh)
#!/bin/bash
# Reads input text, sends to LLM with rewriting prompt
echo "Original text:" > /tmp/input.txt
cat >> /tmp/input.txt
echo "Rewrite this text with different sentence structure, vocabulary, and tone while preserving meaning:" | ollama run mistral
# Expected output: Rewritten text with altered style but same meaning
# Why: Breaks stylometric fingerprints (sentence length, word choice, punctuation)
# Security: Your writing style is as unique as fingerprint—this obscures it
# Use when: Posting anonymously but want to avoid authorship attribution

# Usage: echo "Your text here" | ./rewrite.sh
# Process: Paste sensitive text, get rewritten version, manually review

# Alternative: Translate through multiple languages to scramble style
# Requires: sudo apt install translate-shell
# Multi-language translation introduces grammatical artifacts that break patterns

# Translate English → Spanish → French → English
# trans = translate-shell command
# en:es = English to Spanish, etc.
# | = pipe output to next translation
echo "Your sensitive text" | trans en:es | trans es:fr | trans fr:en
# Expected output: Text with altered structure due to translation artifacts
# Why: Machine translation changes sentence structure, idiom usage, grammar
# Security: Breaks statistical patterns used in stylometry analysis
# Limitation: Can introduce awkward phrasing, requires manual cleanup
# Use when: Need quick obfuscation without AI model

# Style analysis tool to test your anonymity
# Install Anonymouth: https://github.com/psal/anonymouth
# Academic tool that analyzes your writing style and suggests changes

# Clone repository
git clone https://github.com/psal/anonymouth.git
# Expected output: Repository cloned to ./anonymouth/

# Build with Maven
# mvn = Maven build tool for Java projects
# package = compile and package as JAR
cd anonymouth && mvn package
# Expected output: JAR file created in target/ directory
# Why: Need to compile Java source into executable

# Run Anonymouth GUI
# -jar = run Java archive
java -jar target/anonymouth.jar
# Expected output: GUI application opens
# Why: Analyzes your text for identifying features (word frequency, sentence length patterns)
# Security: Shows which stylistic features make you identifiable
# Use when: Testing if your writing is distinctive enough to trace
# Process: Input samples of your writing, tool identifies unique patterns</code></pre>

        <h3>Media Scrubbing</h3>
        <ul>
            <li>Strip location clues in images by editing out skyline reflections, utility labels, and metadata before sharing.</li>
            <li>When releasing video, re-record voiceovers with synthetic filters or double encoding to remove electrical network frequency traces of your grid.</li>
        </ul>
        
        <p><strong>Security Impact:</strong> Photos contain GPS coordinates, camera model, software version, and timestamp. Videos leak even more: electrical network frequency (ENF) embedded in audio reveals your power grid location with city-level accuracy. Background sounds, visible license plates, street signs, and architectural features can all pinpoint location. Even cropped or edited images may retain metadata in EXIF tags.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Strip ALL metadata from images

# Remove all EXIF metadata from photo
# exiftool = Perl-based metadata manipulation tool
# -all= = delete all metadata tags
# --icc_profile:all= = preserve ICC color profile (optional, remove for max privacy)
exiftool -all= --icc_profile:all= photo.jpg
# Expected output: "1 image files updated"
# Creates backup: photo.jpg_original
# Why: Photos contain GPS coordinates, camera model, serial numbers, timestamps
# Security: GPS reveals where you live/work/met sources
# Security: Camera serial links photos across pseudonyms
# Security: Software version reveals your toolchain (Photoshop, GIMP)
# Use when: Sharing any photo publicly or with untrusted parties

# Verify removal
# Lists all remaining metadata tags
exiftool photo.jpg | grep -i gps
exiftool photo.jpg | grep -i camera
# Expected output: No lines (all GPS/camera data removed)
# Why: Confirm metadata actually stripped
# Use when: Paranoid verification before sharing

# Batch process entire directory
# find = search for files
# ~/Pictures = starting directory
# -type f = only files (not directories)
# \( -iname "*.jpg" -o -iname "*.png" \) = match .jpg OR .png (case-insensitive)
# -exec = run command on each match
# exiftool -all= = strip metadata
# -overwrite_original = don't create .jpg_original backups
# {} \; = placeholder for found files, semicolon ends command
find ~/Pictures -type f \( -iname "*.jpg" -o -iname "*.png" \) -exec exiftool -all= -overwrite_original {} \;
# Expected output: "N image files updated"
# Why: Process hundreds of images automatically
# Security: Ensures no images leaked with metadata
# Use when: Cleaning entire photo library before migration/sharing

# Remove ENF from audio (requires ffmpeg with audio filters)
# Apply high-pass filter to remove 50/60Hz hum

# Remove electrical network frequency (ENF) from audio
# ffmpeg = multimedia processing tool
# -i = input file
# -af = audio filter
# "highpass=f=100, lowpass=f=15000" = keep only 100Hz-15kHz (removes 50/60Hz grid hum)
ffmpeg -i input.wav -af "highpass=f=100, lowpass=f=15000" output.wav
# Expected output: Converted audio file without low-frequency hum
# Why: ENF (electrical network frequency) embeds grid frequency in recordings
# Security: ENF analysis can geolocate recording to specific power grid (city-level accuracy)
# How it works: Power grids fluctuate around 50/60Hz, creating unique fingerprint
# Use when: Recording audio in sensitive locations

# Alternative: Add noise to mask ENF
# anoisesrc = audio noise source
# a=0.01 = amplitude (volume) of noise
# -map 0 -map 1 = include both original and noise streams
# -shortest = stop when shortest stream ends
ffmpeg -i input.wav -af "anoisesrc=a=0.01" -map 0 -map 1 -c:v copy -shortest output.wav
# Expected output: Audio with white noise added
# Why: Noise masks ENF pattern, making geolocation impossible
# Trade-off: Slightly degrades audio quality
# Use when: ENF removal alone isn't sufficient

# Scrub video metadata and re-encode to remove fingerprints
# -map_metadata -1 = remove all metadata
# -c:v libx264 = re-encode video with H.264 codec
# -crf 23 = constant rate factor (quality: 0=lossless, 51=worst, 23=good)
# -preset medium = encoding speed/compression trade-off
# -c:a aac = encode audio as AAC
# -b:a 128k = audio bitrate 128 kbps
ffmpeg -i input.mp4 -map_metadata -1 -c:v libx264 -crf 23 -preset medium -c:a aac -b:a 128k output.mp4
# Expected output: Re-encoded video without metadata
# Why: Video metadata includes GPS, camera model, recording date, creator name
# Security: Re-encoding also removes camera sensor noise fingerprints
# Trade-off: Lossy compression (quality reduced)
# Use when: Sharing video that needs maximum privacy

# Check for hidden metadata in PDFs
# exiftool works on PDFs too
exiftool document.pdf
# Expected output: All metadata tags in PDF
# Why: PDFs contain author names, organization, software version, edit history

# pdfinfo = PDF metadata viewer (part of poppler-utils)
pdfinfo document.pdf
# Expected output: Title, author, creator tool, creation/modification dates
# Why: Confirms what metadata exists before cleaning
# Use when: Auditing document before sharing

# Advanced: Rasterize PDF to remove all metadata, form fields, hidden layers
# convert = ImageMagick tool
# -density 300 = render at 300 DPI (good quality)
# -quality 90 = JPEG quality for images
convert -density 300 input.pdf -quality 90 output.pdf
# Expected output: Flattened PDF (each page is image)
# Why: Converts each page to image, destroying all vector data, forms, layers
# Security: Hidden layers with redacted content become truly unreadable
# Security: Form fields with data removed
# Security: Revision history destroyed
# Trade-off: File size increases, text not selectable, quality loss
# Use when: Document contains sensitive metadata or hidden data</code></pre>

        <h3>Behavioral Metadata Discipline</h3>
        <ul>
            <li><strong>Posting cadence:</strong> Queue content to release during randomized windows so sleep patterns or commute habits are not visible.</li>
            <li><strong>Username hygiene:</strong> Never reuse a handle. Run periodic OSINT sweeps with <code>sherlock</code> or <code>maigret</code> to spot collisions. Retire identities if an alias begins cross-linking.</li>
            <li><strong>Contact perimeter:</strong> Segment your social graph. A persona should only interact with accounts it needs for that role. Exposed relationships are an analyst shortcut.</li>
        </ul>
        
        <p><strong>Security Impact:</strong> Behavioral patterns are predictable. If you post every day at 7 AM EST, analysts know your timezone and daily schedule. If you use the same username across platforms, correlation is trivial. If your pseudonymous account follows your real account's friends, social graph analysis links them. Timing attacks, social network analysis, and activity correlation are cheap, automated, and effective.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="python"><code class="language-python">#!/usr/bin/env python3
# Randomized post scheduler to obscure timezone
import random
import schedule
import time
from datetime import datetime, timedelta

def post_content(message):
    """Replace with your posting function (Twitter API, etc)"""
    print(f"[{datetime.now()}] Posting: {message}")
    # YOUR API CALL HERE

def schedule_random_posts(messages, days=7):
    """Schedule posts at random times over N days"""
    start = datetime.now()
    end = start + timedelta(days=days)
    
    for msg in messages:
        # Random time between now and end date
        random_time = start + (end - start) * random.random()
        delay = (random_time - datetime.now()).total_seconds()
        
        if delay > 0:
            print(f"Scheduled: '{msg}' at {random_time}")
            schedule.every(delay).seconds.do(post_content, msg).tag('once')
    
    # Run scheduled tasks
    while schedule.jobs:
        schedule.run_pending()
        time.sleep(60)

# Usage
messages = [
    "Post 1 content",
    "Post 2 content", 
    "Post 3 content"
]
schedule_random_posts(messages, days=7)</code></pre>

        <pre data-lang="bash"><code class="language-bash"># Check username collisions across platforms
# pip3 = Python 3 package installer
# install = download and install from PyPI
pip3 install sherlock-project
# Expected output: Package installed successfully

# Run Sherlock with filtering
# --print-found = only show sites where username exists (suppress "not found")
# --timeout 10 = wait max 10 seconds per site (prevents hanging)
sherlock --print-found --timeout 10 your_test_username
# Expected output: List of websites where username is registered
# Why: Reveals if username is already taken or exposed elsewhere
# Security: Username reuse creates correlation points between accounts
# Use when: Vetting new username before adopting for persona

# More comprehensive scan
# Maigret checks 2500+ sites vs Sherlock's 300+
pip3 install maigret
# Expected output: Package installed

# Run Maigret with timeout
# --timeout 30 = wait up to 30 seconds per site
maigret --timeout 30 your_test_username
# Expected output: Comprehensive report with profile links, metadata
# Why: Deeper OSINT reveals more exposure
# Security: More sites checked = better assessment of username risk
# Use when: High-value personas requiring thorough vetting

# Generate cryptographically random usernames
# Never reuse across personas

# Generate 5 random 12-character usernames
# cat /dev/urandom = read from kernel entropy source (true randomness)
# tr -dc 'a-z0-9' = delete all chars except lowercase letters and numbers
# fold -w 12 = wrap lines at 12 characters
# head -n 5 = take first 5 results
cat /dev/urandom | tr -dc 'a-z0-9' | fold -w 12 | head -n 5
# Expected output: 5 lines of random alphanumeric strings
# Example: x7k2m9p4q1zn
# Why: Cryptographically random = impossible to predict or link
# Security: No human patterns, no dictionary words, no reuse
# Use when: Creating new personas that must be unlinkable

# Or use pwgen for pronounceable names
# Easier to remember than pure random
# Install pwgen (password generator)
sudo apt install pwgen
# Expected output: Package installed

# Generate 5 secure 16-character passwords/usernames
# -s = secure mode (truly random, not pronounceable)
# 16 = character length
# 5 = generate 5 examples
pwgen -s 16 5
# Expected output: 5 random 16-character strings
# Why: pwgen uses /dev/urandom for entropy
# Trade-off: -s makes unpronounceable but maximally random
# Alternative: Remove -s for pronounceable (but slightly less random) names
# Use when: Need memorable but still-secure usernames</code></pre>

        <h2>3. Securing Your Hardware</h2>
        <p>
            If an adversary can touch your device, it is no longer your device. Hardware-rooted attacks bypass software controls entirely, so build defenses from firmware upward.
        </p>
        
        <p><strong>Why This Matters:</strong> Hardware attacks are persistent, stealthy, and often undetectable by software. The NSA's ANT catalog revealed interdiction operations where packages are intercepted during shipping, modified with implants, and resealed. USB devices can contain hidden keystroke loggers, network adapters, or exploit frameworks. Firmware malware (BIOS/UEFI rootkits) survives OS reinstalls and full disk encryption. Hardware is your root of trust: if it's compromised, everything above it is suspect.</p>
        
        <h3>Boot Chain Integrity</h3>
        <ul>
            <li><strong>Evil Maid:</strong> A quick BIOS flash or bootloader swap can harvest your encryption passphrase the next time you power on.</li>
            <li><strong>Defense:</strong> Deploy Heads or Purism PureBoot where possible. On mainstream hardware, bind LUKS to the TPM and a FIDO2 key with <code>systemd-cryptenroll</code> so tampering breaks decryption. Store firmware hashes and check them before every trip.</li>
        </ul>
        
        <p><strong>Security Impact:</strong> "Evil Maid" attacks exploit physical access to modify bootloader code that prompts for your encryption password. The modified bootloader captures your passphrase and either stores it locally or transmits it later. When you type your LUKS password, you're actually giving it to malware. TPM binding prevents this: if firmware or bootloader changes, TPM PCR values change, and the sealed encryption key won't be released. The system refuses to boot.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Bind LUKS encryption to TPM2 + FIDO2 hardware key (multi-factor)
# This requires both the correct firmware state AND physical key presence

# Check TPM2 availability
# Lists available TPM2 devices on system
# --tpm2-device=list = enumerate TPM hardware
systemd-cryptenroll --tpm2-device=list
# Expected output: /dev/tpmrm0 or similar device path
# Why: Verify TPM2 chip exists and is accessible
# Use when: Setting up hardware-backed LUKS encryption

# Enroll LUKS partition with TPM2 (PCRs 0+7: firmware + Secure Boot)
# systemd-cryptenroll = manage LUKS keyslots
# --tpm2-device=auto = automatically detect TPM
# --tpm2-pcrs=0+7 = bind to Platform Configuration Registers 0 and 7
#   PCR 0 = BIOS/UEFI firmware measurements
#   PCR 7 = Secure Boot state
# /dev/nvme0n1p3 = your LUKS-encrypted partition (adjust to your system)
sudo systemd-cryptenroll --tpm2-device=auto --tpm2-pcrs=0+7 /dev/nvme0n1p3
# Expected output: "New TPM2 token enrolled as key slot X"
# Why: TPM seals encryption key to specific firmware state
# Security: If firmware/bootloader modified (Evil Maid attack), PCR values change
# Security: Changed PCRs = TPM refuses to release key = boot fails
# Use when: Protecting against physical tampering during travel

# Add FIDO2 key as second factor (requires key plugged in during boot)
# --fido2-device=auto = automatically detect FIDO2 key (YubiKey, etc.)
sudo systemd-cryptenroll --fido2-device=auto /dev/nvme0n1p3
# Expected output: Prompts to touch FIDO2 key, then "New FIDO2 token enrolled"
# Why: Requires physical hardware key to decrypt
# Security: Even with correct firmware, attacker needs your physical key
# Security: Combines "something you have" (key) with "something it is" (correct firmware)
# Use when: Maximum security against sophisticated attackers

# Verify enrollment
# Lists all keyslots and enrolled tokens
sudo systemd-cryptenroll /dev/nvme0n1p3
# Expected output: Shows TPM2 and FIDO2 tokens in different keyslots
# Why: Confirm multi-factor enrollment succeeded
# Use when: Validating configuration before relying on it

# Test: Reboot should require FIDO2 key + correct firmware state
# If firmware modified, PCRs mismatch and boot fails
# Process:
# 1. System boots, measures firmware into PCRs
# 2. TPM compares current PCRs to sealed values
# 3. If match: TPM releases partial key
# 4. System prompts for FIDO2 key
# 5. User inserts key and touches it
# 6. Keys combined to decrypt LUKS partition
# 7. If any step fails: boot stops

# Baseline firmware hash for integrity checking
# flashrom = tool to read/write firmware chips
# -p internal = use internal programmer (motherboard flash chip)
# -r = read firmware to file
sudo flashrom -p internal -r firmware_baseline.bin
# Expected output: "Reading flash... done"
# Why: Creates baseline for detecting firmware modifications
# Use when: Before travel or leaving device unattended

# Generate SHA256 hash of firmware
# sha256sum = calculate SHA-256 cryptographic hash
sha256sum firmware_baseline.bin > firmware.sha256
# Expected output: Hash written to firmware.sha256
# Why: Small change in firmware = completely different hash
# Store hash in encrypted offline backup

# After travel, verify firmware unchanged
# Read current firmware
sudo flashrom -p internal -r firmware_current.bin
# Expected output: Current firmware saved

# Compare hash to baseline
# -c = check hashes against file
sha256sum -c firmware.sha256
# Expected output: "firmware_baseline.bin: OK" (if unchanged)
# If mismatch: DO NOT BOOT NORMALLY - investigate from live USB
# Why: Hash mismatch = firmware was modified (Evil Maid attack)
# Security: Tampering detected before attacker captures your password
# Use when: Returning from travel through hostile jurisdictions</code></pre>
        
        <h3>Firmware Life Cycle</h3>
        <ul>
            <li>Apply vendor updates only after verifying checksums and signatures. Never flash firmware from the same OS install you are updating.</li>
            <li>Maintain a known-good boot disk so you can reflash from a trusted environment after travel.</li>
            <li>Disable Intel Management Engine or AMD PSP functionality where your hardware allows.</li>
        </ul>
        
        <p><strong>Security Impact:</strong> Firmware updates can introduce backdoors or vulnerabilities. Flashing from a compromised OS means malware can modify the firmware file before it writes to flash memory. Intel ME and AMD PSP run at ring -3 (higher privilege than your kernel) with access to RAM, network, and storage independent of the OS: they're black boxes you can't audit. ME has had remote code execution vulnerabilities (CVE-2017-5689) that enable total system compromise.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Verify firmware update authenticity (example: Lenovo BIOS)
# 1. Download firmware from vendor
# 2. Download checksum file and GPG signature

# Download BIOS update files
# wget = web get (download tool)
wget https://download.lenovo.com/bios_update.iso
wget https://download.lenovo.com/bios_update.iso.sha256
wget https://download.lenovo.com/bios_update.iso.sig
# Expected output: Files downloaded to current directory
# Why: Need firmware + signature + checksum for verification
# Security: Never flash unverified firmware (could be backdoored)

# 3. Import vendor GPG key
# --recv-keys = receive/download key from keyserver
# VENDOR_KEY_ID = replace with actual Lenovo key ID
gpg --recv-keys VENDOR_KEY_ID
# Expected output: "gpg: key XXXXX: public key imported"
# Why: Need vendor's public key to verify their signature
# Note: Get key ID from vendor's website (e.g., Lenovo support page)

# 4. Verify signature
# --verify = check GPG signature matches file
# .sig file = detached signature
gpg --verify bios_update.iso.sig bios_update.iso
# Expected output: "Good signature from 'Lenovo'..."
# Why: Proves file came from vendor and wasn't modified in transit
# Security: Signature mismatch = MITM attack or file corruption
# Use when: Before flashing ANY firmware

# 5. Check checksum
# -c = check checksums from file
sha256sum -c bios_update.iso.sha256
# Expected output: "bios_update.iso: OK"
# Why: Verifies file integrity (no corruption)
# Use when: After signature check (checksums alone don't prove authenticity)

# Flash firmware from TRUSTED environment only
# Boot from Tails or known-good live USB
# NEVER flash from potentially compromised OS
# Why: Malware on OS can modify firmware file before flashing
# Security: Compromised firmware persists across OS reinstalls

# Disable Intel ME (requires me_cleaner - ADVANCED, can brick hardware)
# WARNING: Dangerous! Can permanently damage system. Research thoroughly first.

# Clone me_cleaner repository
# Tool to neutered Intel Management Engine
git clone https://github.com/corna/me_cleaner.git
cd me_cleaner
# Expected output: Repository cloned

# Backup current firmware (CRITICAL - enables recovery if bricked)
# -r = read mode
sudo flashrom -p internal -r backup.bin
# Expected output: "Reading flash... done"
# Why: If cleaning fails, you can restore original firmware
# Store backup.bin on USB drive in safe location

# Run me_cleaner on firmware
# -S = soft disable (safer than full removal)
# -O = output file
python3 me_cleaner.py -S -O cleaned.bin backup.bin
# Expected output: Analysis of ME regions, "Modified" regions listed
# Why: Disables Intel ME while keeping minimum functionality for boot
# Review output carefully before flashing

# Flash cleaned firmware (POINT OF NO RETURN)
# Only proceed if me_cleaner reported success
# -w = write mode
sudo flashrom -p internal -w cleaned.bin
# Expected output: "Writing flash... done"
# System may not boot if ME cleaning incompatible with your hardware
# Why: Intel ME runs at ring -3, has full system access, potential backdoor
# Security: Neutering ME removes Intel's ability to remote access system
# Use when: Maximum paranoia, understand risks

# Check ME status
# intelmetool = tool to query ME status
sudo intelmetool -m
# Expected output: Shows ME version and whether it's enabled/disabled
# Or: sudo apt install intelmetool && intelmetool
# Why: Verify ME is actually disabled
# Use when: After ME cleaning to confirm success

# AMD PSP can be partially disabled in BIOS
# Look for "PSP fTPM" or "Platform Security" options in firmware setup
# Why: AMD's equivalent to Intel ME (ring -3 processor)
# Security: Less tooling available for AMD, BIOS option is safest bet
# Use when: Using AMD system and want to reduce attack surface</code></pre>
        
        <h3>Peripheral and DMA Control</h3>
        <ul>
            <li>Disable unused ports in BIOS and with <code>boltctl</code>. Lock down USB with <code>usbguard generate-policy</code>.</li>
            <li>Carry USB data blockers when charging in public. Treat found media as hostile.</li>
            <li>Audit network cards and webcams before and after border crossings. Photograph serial numbers to confirm they are unchanged.</li>
        </ul>
        
        <p><strong>Security Impact:</strong> USB devices can present as keyboards and type commands, or use DMA to read/write RAM directly. Thunderbolt/PCIe attacks via tools like PCILeech can dump full memory contents including encryption keys in seconds. Public charging stations have been weaponized to install malware ("juice jacking"). Border agents can swap network cards with modified firmware or install hardware implants during "random" secondary screening.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Install USBGuard for USB device whitelisting
# USBGuard = framework for USB device authorization
# Blocks unauthorized USB devices from connecting
sudo apt install usbguard
# Expected output: Package and dependencies installed
# Why: USB devices can be malicious (BadUSB attacks, HID injection)
# Security: Device presents as keyboard, types commands to own system
# Use when: Need to control which USB devices can connect

# Generate policy from currently connected trusted devices
# Only devices currently plugged in will be allowed by default
# generate-policy = create rules based on current devices
sudo usbguard generate-policy > /etc/usbguard/rules.conf
# Expected output: Rules written to config file
# Why: Whitelist known-good devices (your keyboard, mouse, etc.)
# Process: Plug in all trusted devices first, then generate policy

# Start service
# enable = start on boot
# --now = also start immediately
sudo systemctl enable --now usbguard
# Expected output: Service started and enabled
# Why: Activate USB device filtering

# Block all new devices by default
# ImplicitPolicyTarget = what to do with devices not in rules
# block = reject any non-whitelisted device
echo 'ImplicitPolicyTarget=block' | sudo tee -a /etc/usbguard/usbguard-daemon.conf
# Expected output: Setting appended to config
# Why: Default-deny is secure (must explicitly allow devices)

# Restart to apply changes
sudo systemctl restart usbguard
# Expected output: Service restarted

# Allow specific device temporarily
# List connected devices with their IDs
sudo usbguard list-devices
# Expected output: List of USB devices with IDs and status
# Example: 1: allow id 1234:5678 serial "ABC" name "USB Drive"

# Temporarily allow device
# <device-id> = number from list-devices output
sudo usbguard allow-device <device-id>
# Expected output: Device authorization changed
# Why: One-time exception for new trusted device
# To permanently allow: add rule to rules.conf

# Thunderbolt security (requires boltctl)
# Thunderbolt/USB-C allows DMA (direct memory access) attacks
# Tool like PCILeech can dump full RAM in seconds

# Install bolt (Thunderbolt device manager)
sudo apt install bolt
# Expected output: Package installed

# List Thunderbolt devices and authorization status
sudo boltctl list
# Expected output: Connected Thunderbolt devices with security level
# Why: See which devices have DMA access

# Configure "Secure" or "User authorization" in BIOS/UEFI
# This prevents DMA until user explicitly authorizes device
# Security levels:
#   - None: No protection (dangerous)
#   - User: Requires manual authorization (recommended)
#   - Secure: Requires authorization + device supports security
#   - DP only: Only DisplayPort, no PCIe access
# Configure in BIOS: Security > Thunderbolt Security Level

# Document hardware serial numbers BEFORE travel
# Creates baseline for post-travel comparison

# List hardware overview
# lshw = list hardware
# -short = brief format
sudo lshw -short > hardware_baseline.txt
# Expected output: All hardware components listed in file

# List PCI devices with verbose info
# lspci = list PCI devices
# -vvnn = very verbose with numeric IDs
sudo lspci -vvnn > pci_baseline.txt
# Expected output: Detailed PCI device information

# List USB devices with verbose info
# lsusb = list USB devices
# -v = verbose
sudo lsusb -v > usb_baseline.txt
# Expected output: Detailed USB device tree

# Hash MAC addresses of network interfaces
# /sys/class/net/*/address = kernel's network interface MAC addresses
# Hashing prevents casual viewing but allows comparison
sha256sum /sys/class/net/*/address > mac_baseline.txt
# Expected output: Hash of each network interface MAC
# Why: Detect if network card swapped (different MAC)

# After travel/border crossing, compare
# Generate current hardware snapshot
sudo lshw -short > hardware_current.txt
# Compare to baseline
# diff = show differences between files
diff hardware_baseline.txt hardware_current.txt
# Expected output: No output if identical (good)
# If differences shown: investigate what changed
# Why: New hardware = potential implant installed

# Check for unexpected PCI devices
# grep = filter output
# -i = case insensitive
lspci | grep -i network
lspci | grep -i wireless
# Expected output: Should match baseline
# Why: Extra network card = potential monitoring device

# Physical inspection checklist:
# 1. Compare webcam serial number to photo
# 2. Check for new USB devices inside case
# 3. Verify network card MAC address matches baseline
# 4. Inspect PCIe slots for added cards
# 5. Check keyboard cable for inline hardware keyloggers
# Why: Many implants are physical (USB keyloggers, PCIe devices)
# Use when: Device was out of sight (hotel, repair shop, border crossing)</code></pre>
        
        <h3>Operating System Hardening</h3>
        <ul>
            <li>Use Linux distributions that ship with Secure Boot enforcement and minimal telemetry, such as Qubes OS, Tails, or Fedora Silverblue.</li>
            <li>For Windows-only applications, prefer a virtual machine with GPU passthrough and snapshots. Keep host and guest networks segmented with VLANs.</li>
        </ul>
        
        <p><strong>Security Impact:</strong> Mainstream OSes contain telemetry, automatic updates that can introduce backdoors, and large attack surfaces. Qubes OS enforces isolation via Xen hypervisor: compromising a VM doesn't affect others. Tails is amnesic (forgets everything on shutdown) and routes traffic through Tor. Secure Boot prevents rootkits. VM snapshots let you roll back after testing suspicious files.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Install Qubes OS (recommended for high-threat users)
# Download: https://www.qubes-os.org/downloads/
# Verify ISO signature

# Import Qubes OS signing key
# Master signing key for Qubes releases
gpg --import qubes-release-signing-key.asc
# Expected output: Key imported
# Why: Need to verify ISO isn't tampered

# Verify ISO signature against downloaded ISO
# --verify = check detached signature
# Qubes-*.iso.asc = signature file
# Qubes-*.iso = actual ISO image
gpg --verify Qubes-*.iso.asc Qubes-*.iso
# Expected output: "Good signature from 'Qubes OS Release X Signing Key'"
# Why: Proves ISO is authentic from Qubes project
# Security: Prevents installing backdoored OS
# Use when: Before installing Qubes (or any OS)

# After install, create isolated VMs per persona
# qvm-create = create new Qube (VM)
# --template debian-12 = base template to clone
# --label blue = color code for easy identification
# work = name of new VM
qvm-create --template debian-12 --label blue work
# Expected output: VM 'work' created
# Why: Separate VM for work activities

# Create anonymous VM using Whonix (Tor-based)
# whonix-gw-17 = Whonix gateway (routes through Tor)
# --label red = red color = danger/untrusted
# anon = name for anonymous persona
qvm-create --template whonix-gw-17 --label red anon
# Expected output: VM 'anon' created
# Why: All traffic from this VM routes through Tor automatically
# Security: IP address hidden, suitable for anonymous activities

# Configure network isolation
# qvm-prefs = set VM preferences
# netvm = network VM (which VM provides network)
# sys-firewall = Qubes firewall VM (filters traffic)
qvm-prefs work netvm sys-firewall
# Expected output: Property set
# Why: work VM uses firewall for internet (normal)

# Route anon VM through Whonix gateway
# sys-whonix = Whonix gateway VM (Tor proxy)
qvm-prefs anon netvm sys-whonix
# Expected output: Property set
# Why: All traffic from 'anon' goes through Tor
# Security: Impossible for anon VM to bypass Tor
# Use when: Need guaranteed anonymity for VM

# Fedora Silverblue (immutable OS, harder to persist malware)
# Applies updates atomically, can rollback

# Check current OS deployment
# rpm-ostree = atomic OS update manager
# status = show current and available versions
sudo rpm-ostree status
# Expected output: List of OS deployments with booted one marked
# Why: See current version and available rollback points

# Rollback to previous version
# Useful if update breaks something or installs malware
sudo rpm-ostree rollback
# Expected output: Previous deployment will boot next time
# Why: Immutable OS = each version is snapshot
# Security: Malware can't easily persist across rollbacks
# Use when: System behaving suspiciously after update

# Tails for temporary high-risk operations
# Boot from USB, all RAM wiped on shutdown
# Download: https://tails.boum.org/install/
# Why: Amnesic OS = forgets everything on shutdown
# Security: No persistence = no forensic traces
# Use when: One-time high-risk operations (meet source, access leaked data)

# Windows in KVM with GPU passthrough (for games/proprietary software)
# Install virt-manager

# Install QEMU/KVM virtualization stack
# qemu-kvm = emulator and virtualizer
# virt-manager = GUI for managing VMs
sudo apt install qemu-kvm virt-manager
# Expected output: Virtualization packages installed
# Why: Run Windows VMs for software that requires it
# Security: Isolate Windows from Linux host

# Create Windows VM with snapshots enabled
# Isolate on separate VLAN (requires managed switch)
# Revert to snapshot after each session to remove any malware

# Snapshot workflow
# virsh = libvirt management tool
# snapshot-create-as = create named snapshot
# windows10 = VM name
# clean_state = snapshot name
virsh snapshot-create-as windows10 clean_state
# Expected output: Snapshot created
# Why: Save known-good state before risky activities

# Do risky activity in VM (test software, open suspicious files)

# Revert to clean snapshot
# snapshot-revert = restore to previous state
virsh snapshot-revert windows10 clean_state
# Expected output: VM reverted to snapshot
# Why: Any malware installed during session is wiped
# Security: Each session starts from clean slate
# Use when: Testing untrusted software or browsing risky sites</code></pre>

        <h2>4. Separating Your Online Identities</h2>
        <p>
            Compartmentalization ensures that compromise in one persona does not spill into another. Build silos at the browser, VM, and hardware levels depending on risk.
        </p>
        
        <p><strong>Why This Matters:</strong> Every online action creates linkable data points. Reusing email addresses, passwords, usernames, or browser fingerprints across contexts allows correlation. If one identity is compromised (data breach, social engineering, traffic analysis), proper compartmentalization prevents the attacker from pivoting to your other identities. Without isolation, a single leak can expose your entire digital life: work, personal, activist, or pseudonymous personas all collapsing into one.</p>
        
        <h3>Silo Design Principles</h3>
        <ul>
            <li>Assign dedicated hardware security keys or passkeys per persona. Never reuse a credential even if the key supports multiple accounts.</li>
            <li>Create burner email aliases with a forwarding service that supports PGP. Tag each alias so leaks are visible.</li>
            <li>Store documents in encrypted containers named generically. Labeling folders with persona names becomes an OSINT gift if the system is seized.</li>
        </ul>
        
        <p><strong>Security Impact:</strong> Password reuse means one breach compromises all accounts. Browser fingerprints (canvas, WebGL, fonts, screen resolution, timezone) can track you across sites even without cookies. Metadata in filenames ("activist_persona_notes.txt") or folder structures reveals relationships during forensic analysis. Dedicated FIDO2 keys per persona prevent credential reuse. Email aliasing with tags (persona+tag@domain.com) identifies leaks: if you get spam at persona+reddit@domain.com, you know Reddit leaked or sold your data.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Email aliasing with SimpleLogin (open source, selfhostable)
# Install: https://github.com/simple-login/app
# Or use hosted: https://simplelogin.io

# Create tagged aliases for each service
# persona_reddit@simplelogin.com
# persona_forum@simplelogin.com
# If one leaks, you know exactly where
# Why: Tagged emails identify leak source
# Security: If spam appears at persona_reddit@, Reddit leaked/sold your data
# Use when: Signing up for services with pseudonymous identity

# Self-hosted email aliasing with Postfix
# Add to /etc/postfix/virtual:
# Left side = alias received by mail server
# Right side = where to forward it
persona+reddit@yourdomain.com    real_inbox@yourdomain.com
persona+forum@yourdomain.com     real_inbox@yourdomain.com
# Why: + addressing works with most mail servers
# Security: Each service gets unique address

# Reload: sudo postmap /etc/postfix/virtual && sudo systemctl reload postfix
# postmap = compile virtual alias database
# systemctl reload = apply config changes without dropping connections
# Expected output: Virtual alias database updated, service reloaded

# Generate unique passwords per identity with KeePassXC
# Install

# Install KeePassXC password manager
# Offline, open-source, cross-platform
sudo apt install keepassxc
# Expected output: Package installed
# Why: Need secure storage for unique passwords per identity
# Security: Encrypted database with Argon2id key derivation
# Use when: Managing multiple personas with distinct passwords

# Create separate database per persona
# db-create = create new KeePassXC database
# persona_work.kdbx = encrypted database file
keepassxc-cli db-create persona_work.kdbx
# Expected output: Prompts for master password, then creates database
# Why: Separate database = separate master password = isolation

keepassxc-cli db-create persona_anon.kdbx
# Expected output: Anonymous persona database created
# Why: If one database compromised, others remain safe

# Generate password
# generate = create random password
# -L 32 = length 32 characters
# -l = include lowercase
# -u = include uppercase
# -n = include numbers
# -s = include symbols
keepassxc-cli generate -L 32 -l -u -n -s
# Expected output: Random 32-char password
# Why: Cryptographically random, high entropy
# Security: Impossible to guess or crack

# Store with URL and notes
# add = add entry to database
# persona_work.kdbx = which database
# Reddit = entry title
# -u = username
# --url = associated website
keepassxc-cli add persona_work.kdbx Reddit -u persona+reddit@domain.com --url https://reddit.com
# Expected output: Prompts for password (use generated one)
# Why: Store password with context (which service, which username)
# Use when: Creating accounts for work persona

# Dedicated FIDO2 keys per persona (YubiKey, SoloKeys, Nitrokey)
# Register work key to work accounts ONLY
# Register personal key to personal accounts ONLY
# Never cross-contaminate
# Why: Hardware keys can't be phished
# Security: Each key authenticates distinct persona
# Use when: Setting up 2FA for high-value accounts

# Check FIDO2 key info
# fido2-token = tool for FIDO2 key management
# -L = list connected FIDO2 devices
fido2-token -L
# Expected output: List of FIDO2 device paths (/dev/hidraw0, etc.)
# Why: Verify key is recognized by system

# Get detailed info about key
# -I = info about specific device
fido2-token -I /dev/hidraw0
# Expected output: Key version, supported features, resident key info
# Why: Confirm key capabilities before use

# Encrypted containers for persona documents (VeraCrypt)

# Install VeraCrypt
sudo apt install veracrypt
# Expected output: VeraCrypt installed
# Why: Need encrypted containers for sensitive per-persona files

# Create container (generic name, no identifying info)
# veracrypt = encryption tool
# --text = command-line mode (no GUI)
# --create = create new volume
# /home/user/data.vc = container file path (generic name!)
# --size=1G = 1 gigabyte container
# --volume-type=normal = standard volume (not hidden)
# --encryption=AES = AES-256 encryption
# --hash=SHA-512 = hash for key derivation
# --filesystem=ext4 = Linux filesystem inside container
veracrypt --text --create /home/user/data.vc --size=1G --volume-type=normal --encryption=AES --hash=SHA-512 --filesystem=ext4
# Expected output: Prompts for password, creates encrypted container
# Why: Generic filename (data.vc not activist_docs.vc) to avoid revealing contents
# Security: Even container name is metadata

# Mount with generic mountpoint
# Mount = make container accessible as filesystem
# /mnt/temp = generic mount point (not /mnt/activist_files)
veracrypt --text /home/user/data.vc /mnt/temp
# Expected output: Prompts for password, mounts to /mnt/temp
# Why: Access encrypted files while maintaining plausible deniability

# Inside container, organize carefully
# Avoid filenames with persona names
# Use codes: "proj_alpha" not "activist_campaign"
# Why: If container seized and cracked, filenames reveal operation
# Security: Generic names maintain operational security even if encryption broken
# Use when: Storing sensitive documents for pseudonymous personas</code></pre>
        
        <h3>Browser Fingerprinting Resistance</h3>
        <p>
            Use Tor Browser or Mullvad Browser to standardize window size, fonts, and canvas output. Avoid installing extra extensions. Never maximize the window and clear first-party isolation when rotating identities.</p>
        
        <p><strong>Security Impact:</strong> Browser fingerprinting can uniquely identify you even in private mode or with VPN. Panopticlick studies show 83% of browsers have unique fingerprints based on: user agent, screen resolution, installed fonts, WebGL renderer, canvas rendering, audio context, timezone, language, and plugins. Tor Browser combats this by making all users look identical. Maximizing the window leaks screen resolution. Extensions add identifying characteristics.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Install Tor Browser (fingerprinting-resistant by design)
# Download from: https://www.torproject.org/download/

# Navigate to downloads folder
cd ~/Downloads

# Extract Tor Browser bundle
# tar = archive tool
# -xf = extract file
tar -xf tor-browser-*.tar.xz
# Expected output: Files extracted to tor-browser/ directory
# Why: Tor Browser is distributed as tarball, not package

# Navigate into extracted directory
cd tor-browser

# Launch Tor Browser
# .desktop file = Linux app launcher
./start-tor-browser.desktop
# Expected output: Tor Browser launches, connects to Tor network
# Why: Tor Browser makes all users look identical (anti-fingerprinting)
# Security: Routes through 3 random Tor relays, hides your IP
# Security: Standardized window size, fonts, settings = homogeneous fingerprint
# Use when: Need anonymity (whistleblowing, circumventing censorship)

# Or Mullvad Browser (Tor Browser without Tor network)
# Download: https://mullvad.net/en/download/browser
# Extract and run
# Why: Same anti-fingerprinting as Tor Browser but faster (no Tor routing)
# Security: Good for privacy without anonymity
# Use when: ISP surveillance is concern but don't need Tor-level anonymity

# CRITICAL: Never maximize window (leaks screen resolution)
# Use default size only
# Why: Screen resolution is fingerprinting datapoint
# Security: Maximized window reveals your exact monitor dimensions
# Everyone using default size = identical fingerprint

# Never install additional extensions
# Why: Extensions make your browser unique
# Security: Even privacy extensions add identifying characteristics
# Use when: Maintaining anonymity with Tor Browser

# Clear cookies between persona sessions
# Why: Cookies track you across sessions
# Tor Browser does this automatically on close

# Test fingerprint uniqueness
# Visit in Tor Browser: https://coveryourtracks.eff.org/
# Should show "strong protection against tracking"
# Why: EFF's tool tests browser fingerprinting resistance
# Expected result: "Your browser has a randomized fingerprint" (good)
# If "Your browser has a unique fingerprint" (bad - you're trackable)

# Firefox hardening for non-Tor use (user.js)
# Download Arkenfox user.js: https://github.com/arkenfox/user.js

# Navigate to Firefox profile directory
# *.default-release = your default profile folder
cd ~/.mozilla/firefox/*.default-release/
# Expected: Changes to Firefox profile directory

# Download Arkenfox user.js (privacy-hardening config)
# wget = web get
wget https://raw.githubusercontent.com/arkenfox/user.js/master/user.js
# Expected output: user.js downloaded
# Why: Arkenfox configures ~3000 Firefox privacy settings
# Security: Disables telemetry, enables tracking protection, hardens fingerprinting
# Use when: Using Firefox instead of Tor Browser but want privacy

# Restart Firefox
# Settings automatically applied on next launch
# Why: user.js overrides default Firefox config

# LibreWolf (pre-hardened Firefox fork)
# Install

# Enable extrepo (Debian external repository tool)
sudo apt install extrepo
# Expected output: Package installed

# Enable LibreWolf repository
# extrepo = manages external repos safely
sudo extrepo enable librewolf
# Expected output: LibreWolf repo added

# Update package list and install
sudo apt update && sudo apt install librewolf
# Expected output: LibreWolf browser installed
# Why: LibreWolf = Firefox with privacy by default (includes Arkenfox-like settings)
# Security: No telemetry, uBlock Origin preinstalled, tracking protection enabled
# Use when: Want privacy-respecting browser without manual configuration

# Create isolated profiles per persona
# -ProfileManager = launch Firefox profile manager
# -no-remote = allow multiple Firefox instances simultaneously
firefox -ProfileManager -no-remote
# Expected output: Profile manager window opens
# Why: Separate profiles = separate cookies, history, extensions
# Security: Profile isolation prevents cross-persona tracking

# Create: work_profile, personal_profile, anon_profile
# Process: Click "Create Profile", name it, assign to persona

# Launch specific profile:
# -P profile_name = launch with specific profile
# -no-remote = run alongside other instances
# & = run in background
firefox -P work_profile -no-remote &
firefox -P anon_profile -no-remote &
# Expected output: Two Firefox windows, different profiles
# Why: Work and anonymous browsing isolated in separate profiles
# Security: Cookies from work profile can't track anonymous profile
# Use when: Managing multiple personas on same machine

# Use containers addon for tab-level isolation (Firefox)
# Install Multi-Account Containers
# Why: Containers isolate cookies/storage within same profile
# Security: "Work" container separate from "Personal" container
# Use when: Need lightweight isolation without multiple profiles

# Assign tabs to containers (work, personal, shopping)
# Cookies/storage isolated between containers
# Why: Facebook in "Social" container can't see your banking cookies in "Finance" container
# Security: Prevents cross-site tracking within single browser session</code></pre>
        
        <h3>Identity Lifecycle</h3>
        <ol>
            <li>Expire identities on a schedule and record the retirement date in a secure ledger.</li>
            <li>Delete accounts and request GDPR or CCPA erasure when an identity retires or leaks.</li>
            <li>Revoke PGP, SSH, and API keys. Remove OAuth grants in linked services.</li>
            <li>Wipe associated VMs or browser profiles and destroy recovery media.</li>
            <li>Seed new identities with mundane activity before critical use so behavior looks organic.</li>
        </ol>
        
        <p><strong>Security Impact:</strong> Long-lived identities accumulate data and exposure over time. A 5-year-old account has interacted with thousands of people, services, and datasets: each a potential correlation point. Regular rotation limits damage from breaches. GDPR Article 17 and CCPA give legal right to deletion, forcing companies to purge your data. OAuth tokens persist even after password changes, allowing continued access. Freshly created accounts exhibiting sophisticated behavior look suspicious (automated/bot-like); aging them with normal activity creates cover.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Identity retirement checklist (save as retire_identity.sh)
#!/bin/bash
# Script to systematically retire a pseudonymous identity
# Usage: ./retire_identity.sh persona_name

IDENTITY="$1"  # First argument = identity name
DATE=$(date +%Y-%m-%d)  # Current date in YYYY-MM-DD format

echo "Retiring identity: $IDENTITY on $DATE"

# 1. Document retirement
# Append retirement record to ledger
# >> = append to file (don't overwrite)
echo "$IDENTITY retired $DATE" >> ~/.identity_ledger.txt
# Why: Maintain audit trail of identity lifecycles
# Security: Know which identities are active vs retired

# 2. Revoke PGP key
# List keys to confirm correct one
# --list-keys = show public keys
gpg --list-keys "$IDENTITY"
# Expected output: Key details for identity

# Generate revocation certificate
# --gen-revoke = create revocation cert
gpg --gen-revoke "$IDENTITY" > "$IDENTITY-revoke.asc"
# Expected output: Revocation cert saved
# Why: Invalidates PGP key so it can't be used

# Import revocation (applies it locally)
# --import = add revocation to keyring
gpg --import "$IDENTITY-revoke.asc"
# Expected output: Key revoked

# Publish revocation to keyservers
# --send-keys = upload key (now revoked) to keyserver
# KEYID = replace with actual key ID from --list-keys
gpg --send-keys KEYID
# Expected output: Key uploaded
# Why: Others' systems will learn key is revoked
# Security: Prevents future use of compromised/retired key

# 3. Delete SSH keys
# rm = remove files
rm ~/.ssh/id_rsa_$IDENTITY
rm ~/.ssh/id_rsa_$IDENTITY.pub
# Expected output: Keys deleted
# Remove from authorized_keys on all servers
# Why: Prevent SSH access with old identity keys
# Security: Revoke access to servers used by this persona
# Manual step: SSH to each server, edit ~/.ssh/authorized_keys

# 4. Revoke OAuth tokens (example: GitHub)
# Visit: https://github.com/settings/applications
# Revoke all for this identity
# Why: OAuth tokens persist after password change
# Security: GitHub, Google, etc. can still access account via old tokens
# Manual step: Visit each service's OAuth settings page

# 5. Request GDPR deletion (template)
# cat > file = create file with following content
# << 'EOF' = here-document (text until EOF)
cat > gdpr_deletion_$IDENTITY.txt << 'EOF'
Subject: GDPR Article 17 Right to Erasure Request

To whom it may concern,

I request immediate and complete deletion of all personal data 
associated with my account under GDPR Article 17 (Right to Erasure).

Account details:
Email: $IDENTITY@domain.com
Username: $IDENTITY

Please confirm deletion within 30 days as required by law.

Thank you.
EOF
# Expected output: Email template created
# Why: GDPR gives EU residents right to deletion
# Security: Forces services to purge your data
# Manual step: Send this email to each service used by identity

# 6. Wipe browser profile
# rm -rf = remove recursively and forcefully
# *.$IDENTITY = glob pattern matching identity-named profiles
rm -rf ~/.mozilla/firefox/*.$IDENTITY/
rm -rf ~/.config/chromium/$IDENTITY/
# Expected output: Browser profiles deleted
# Why: Remove browsing history, cookies, saved passwords
# Security: Forensic analysis can't recover deleted profiles

# 7. Delete email account (if self-hosted)
# Or close external accounts
# Manual step: Depends on email provider
# Self-hosted: userdel command or email admin panel
# External: Account deletion page on provider site

# 8. Shred documents
# shred = secure file deletion (overwrites before deleting)
# -vfz = verbose, force, zero-fill after shredding
# -n 7 = overwrite 7 times (DoD 5220.22-M standard)
shred -vfz -n 7 ~/Documents/$IDENTITY/*
# Expected output: Files overwritten and deleted
# Why: Normal deletion leaves data recoverable
# Security: 7-pass overwrite makes recovery extremely difficult

# 9. Remove encrypted containers
# Dismount VeraCrypt container
# --dismount = unmount volume
veracrypt --text --dismount /mnt/$IDENTITY
# Expected output: Volume dismounted

# Shred container file
# -n 3 = 3 passes sufficient for encrypted data
shred -vfz -n 3 ~/data_$IDENTITY.vc
# Expected output: Container file overwritten and deleted
# Why: Encrypted container itself is evidence of secrets
# Security: Remove even existence of container

echo "Identity $IDENTITY retired successfully"

# New identity seeding (appear human, not bot)
# Schedule organic-looking activity over 2-3 months:
# - Browse news sites
# - Comment on low-stakes topics
# - Follow/unfollow accounts gradually
# - Post mundane content
# - React to others' posts
# Only after "aging" period, use for sensitive activity
# Why: Fresh accounts with sophisticated activity look automated/suspicious
# Security: Aged accounts blend in with normal users
# Use when: Creating replacement persona after retirement</code></pre>

        <h2>5. Passwords and Authentication</h2>
        <p>
            Humans are predictably bad at randomness. Delegate entropy to physical processes and enforce hardware-backed MFA everywhere it is supported. NIST SP 800-63B recommends at least eight characters for user-chosen secrets and supports passphrase length over forced complexity.
        </p>
        
        <p><strong>Why This Matters:</strong> Password reuse across sites means a breach at one low-security forum compromises your email, banking, and cloud storage. Credential stuffing attacks test billions of leaked username/password pairs against major services daily. Weak passwords (dictionary words, dates, names) fall to offline cracking in seconds. Even "strong" passwords like "P@ssw0rd!" are in common wordlists. Two-factor authentication via SMS is vulnerable to SIM swapping attacks. Only cryptographic hardware keys (FIDO2/WebAuthn) resist phishing and real-time man-in-the-middle attacks.</p>
        
        <ul>
            <li>Generate passphrases with Diceware and at least six words. Record a checksum so you can confirm future transcriptions.</li>
            <li>Use a password manager that permits offline storage and custom keyfiles, such as KeePassXC with Argon2id hardening.</li>
            <li>Store TOTP seeds offline so device loss does not break access. Export them as encrypted JPEG QR backups stored in an air-gapped vault.</li>
            <li>Enroll at least two hardware security keys compliant with FIDO2 or WebAuthn. Keep one sealed in a tamper-evident bag at an offsite location.</li>
            <li>Configure recovery workflows. Use stored recovery codes, but treat them as sensitive secrets. If a service supports passkeys, bind them to dedicated platform authenticators per persona.</li>
        </ul>
        <p>
            Review authentication logs weekly. Rate-limit SSH and web services with tools like <code>fail2ban</code> and adopt challenge-response where available.
        </p>
        
        <p><strong>Security Impact:</strong> Diceware generates passwords with ~77 bits of entropy (6 words from 7776-word list: $7776^6 ≈ 2^{77}$), making brute force infeasible. KeePassXC's Argon2id key derivation takes seconds to unlock but makes offline cracking prohibitively expensive. TOTP seeds (shared secrets) are phishable: attacker gets your code, they're in. FIDO2 keys use public-key cryptography: private key never leaves hardware, so phishing sites can't steal it. Recovery codes bypass all security if leaked. Fail2ban blocks IPs after failed login attempts, stopping brute force attacks.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Generate Diceware passphrase (6 words = ~77 bits entropy)
# Requires physical dice for true randomness
# Download wordlist: https://theworld.com/~reinhold/diceware.wordlist.asc

# Roll 5 dice, read as 5-digit number, look up word
# Repeat 6 times
# Example: "cleft cam synod lacy yr wok"
# Why: 6 words from 7776-word list = 7776^6 ≈ 2^77 combinations
# Security: 77 bits entropy = infeasible to brute force
# Use when: Creating master passwords for password managers

# Automated (uses /dev/random for entropy)
# Download and verify Diceware wordlist
wget https://theworld.com/~reinhold/diceware.wordlist.asc
# Expected output: Wordlist downloaded

# Verify signature first
# (Skipped here, but gpg --verify in production)
gpg --verify diceware.wordlist.asc
# Expected output: Good signature
# Why: Ensure wordlist not tampered (backdoored word list = weak passwords)

# Generate passphrase programmatically
# for i in {1..6} = loop 6 times (6 words)
# od = octal dump, reads random bytes
# -An = no address column
# -N3 = read 3 bytes
# -i = interpret as integer
# awk '{print $1 % 7776 + 1}' = convert to number 1-7776
# grep "^$NUM" = find line starting with that number
# cut -f2 = extract second field (the word)
for i in {1..6}; do
  NUM=$(od -An -N3 -i /dev/random | awk '{print $1 % 7776 + 1}')
  grep "^$NUM" diceware.wordlist.asc | cut -f2
done | tr '\n' ' '
echo
# Expected output: "cleft cam synod lacy yr wok" (6 random words)
# Why: /dev/random uses kernel entropy (hardware noise, interrupts)
# Security: True randomness, not pseudo-random
# Use when: Generating high-security passphrases

# Calculate checksum for verification
# sha256sum = hash passphrase
# cut -c1-8 = take first 8 characters of hash
echo "cleft cam synod lacy yr wok" | sha256sum | cut -c1-8
# Expected output: 8-character hex string (e.g., "a3f7d2c1")
# Record checksum with passphrase storage
# Why: Verify you typed passphrase correctly later
# Use when: Storing passphrase in safe deposit box

# KeePassXC setup with Argon2id hardening

# Install KeePassXC
sudo apt install keepassxc
# Expected output: Package installed

# Create database with strong KDF
# db-create = create new database
# --set-key-file = use keyfile in addition to password
# keyfile.key = random file acting as second factor
keepassxc-cli db-create --set-key-file keyfile.key passwords.kdbx
# Expected output: Prompts for password, creates database
# Why: Password + keyfile = two-factor protection
# Security: Attacker needs both password AND keyfile
# Use when: Storing high-value credentials

# Configure Argon2id (done via GUI or edit XML)
# Settings > Database Settings > Encryption
# Algorithm: Argon2id
# Memory: 1 GB (prevents GPU cracking)
# Parallelism: 8 threads
# Iterations: 10 (adjust for ~1 second unlock time)
# Why: Argon2id is memory-hard = expensive for attackers to crack
# Security: 1GB memory requirement defeats GPU/ASIC crackers
# Trade-off: Takes 1 second to unlock (acceptable for human use)

# Add entry
# add = create new entry
# passwords.kdbx = database file
# GitHub = entry name
# --username = account username
# --url = associated website
# --generate = auto-generate password
# --length 32 = 32-character password
keepassxc-cli add passwords.kdbx GitHub \
  --username "your_username" \
  --url "https://github.com" \
  --generate --length 32
# Expected output: Prompts for database password, creates entry
# Why: Unique 32-char password per service
# Security: If GitHub breached, other accounts remain safe

# Backup TOTP seeds securely
# In KeePassXC, right-click entry > TOTP > Show QR code
# Screenshot and encrypt:

# Encrypt screenshot of TOTP QR code
# --encrypt = encrypt file
# --recipient = your GPG key
gpg --encrypt --recipient your@email.com totp_github_qr.png
# Expected output: totp_github_qr.png.gpg created
# Why: TOTP seed (QR code) is shared secret
# Security: If phone lost, encrypted backup restores 2FA

# Or export as text and encrypt
# show = display entry
# -a TOTP = show TOTP attribute
# | gpg = pipe to GPG for encryption
keepassxc-cli show passwords.kdbx GitHub -a TOTP | gpg --encrypt -r your@email.com > totp_github.gpg
# Expected output: Encrypted TOTP seed saved
# Store encrypted TOTP backups on offline USB in safe
# Why: Device-independent 2FA recovery

# Enroll FIDO2 hardware keys (buy 2+ keys)
# YubiKey, SoloKeys, Nitrokey, or Google Titan

# Test key
# fido2-token -L = list FIDO2 devices
fido2-token -L
# Expected output: /dev/hidraw0 or similar
# Why: Verify system recognizes key

# Get device info
# -I = info about device
fido2-token -I /dev/hidraw0
# Expected output: Manufacturer, version, capabilities
# Why: Confirm key model and features

# Register key with services (example: GitHub)
# Settings > Password and authentication > Security keys
# Follow prompts to touch key
# Why: Hardware keys can't be phished (private key never leaves device)
# Security: Phishing site can't steal key, only works on real domain

# CRITICAL: Enroll backup key immediately
# Store backup key in safe deposit box or trusted location
# If primary key lost, backup key prevents account lockout
# Why: Single key = single point of failure
# Use when: Setting up any FIDO2-protected account

# Export recovery codes and encrypt
# Save recovery codes from each service

# Create recovery codes file
echo "GitHub recovery codes:" > recovery_codes.txt
echo "abc-def-ghi" >> recovery_codes.txt
echo "jkl-mno-pqr" >> recovery_codes.txt
# Add all recovery codes

# Encrypt recovery codes
gpg --encrypt --recipient your@email.com recovery_codes.txt
# Expected output: recovery_codes.txt.gpg created

# Securely delete plaintext
# shred = securely delete file
# -vfz = verbose, force, zero-fill
# -n 3 = overwrite 3 times
shred -vfz recovery_codes.txt
# Expected output: File overwritten and deleted
# Why: Recovery codes bypass all 2FA
# Security: If leaked, attacker gains full access
# Store recovery_codes.txt.gpg on offline encrypted USB

# SSH with hardware key (YubiKey)
# Generate resident key on hardware
# ssh-keygen = SSH key generator
# -t ed25519-sk = Ed25519 key on security key
# -O resident = store key on hardware (can be recovered)
# -O application=ssh:YubiKey = namespace for key
ssh-keygen -t ed25519-sk -O resident -O application=ssh:YubiKey
# Expected output: Prompts to touch key, creates keypair
# Private key lives on YubiKey, can't be extracted
# Requires physical touch to use
# Why: SSH key protected by hardware
# Security: Stolen laptop doesn't expose SSH key
# Use when: SSH to production servers

# Configure fail2ban for SSH brute force protection

# Install fail2ban
sudo apt install fail2ban
# Expected output: Package installed
# Why: Automatically bans IPs after failed login attempts

# Create jail for SSH
# tee = write to file (as sudo)
sudo tee /etc/fail2ban/jail.local << 'EOF'
[sshd]
enabled = true        # Activate this jail
port = ssh            # Monitor SSH port (22)
filter = sshd         # Use sshd log pattern
logpath = /var/log/auth.log  # Where to read logs
maxretry = 3          # Ban after 3 failed attempts
bantime = 3600        # Ban for 1 hour (3600 seconds)
findtime = 600        # 3 failures within 10 minutes triggers ban
EOF
# Expected output: Config written
# Why: Stops SSH brute force attacks
# Security: Attacker gets 3 tries, then IP blocked for 1 hour

# Enable and start fail2ban
sudo systemctl enable --now fail2ban
# Expected output: Service started and enabled

# Check SSH jail status
# fail2ban-client = control tool
# status sshd = show sshd jail statistics
sudo fail2ban-client status sshd
# Expected output: Current bans, total banned, failed attempts
# Why: Monitor attacks on your SSH
# Use when: Checking if system under attack

# Review authentication logs weekly
# Check for unauthorized attempts

# View SSH authentication failures from last week
# journalctl = systemd journal viewer
# -u sshd = only sshd service
# --since = time range
# | grep = filter output
sudo journalctl -u sshd --since "1 week ago" | grep "Failed password"
# Expected output: List of failed login attempts with IPs
# Why: Identify persistent attackers or unusual patterns

# Check successful logins
# last = show login history
# -f /var/log/wtmp = use wtmp log file
sudo last -f /var/log/wtmp
# Expected output: List of successful logins with timestamps
# Why: Detect unauthorized access
# Look for: unfamiliar IPs, odd hours, unknown usernames

# Check failed login attempts
# lastb = show bad (failed) login attempts
sudo lastb
# Expected output: Failed login attempts
# Why: See who's trying to break in
# Use when: Weekly security audit</code></pre>

        <h2>6. Private Communication</h2>
        <p>
            Encryption only matters when the protocol, implementation, and operational discipline align. Choose the medium that fits your threat model and verify keys every time something sensitive changes hands.
        </p>
        
        <p><strong>Why This Matters:</strong> Unencrypted communication is readable by your ISP, VPN provider, email server, messaging platform, and any government with access to backbone infrastructure. Even encrypted messaging can leak metadata: who talks to whom, when, how often, and message sizes. Protocol choice matters: Signal has been subpoenaed but can only provide account creation date and last connection time. Traditional SMS/phone calls have no encryption and leak full content plus location. Email encryption (PGP) protects content but leaves metadata exposed.</p>
        
        <ul>
            <li><strong>Signal:</strong> Best balance of usability and security, but phone-number bound. Use registration lock PINs and review linked devices regularly.</li>
            <li><strong>Session:</strong> Signal-derived without phone numbers, using Lokinet for routing. The absence of phone identifiers lowers metadata leakage.</li>
            <li><strong>Briar:</strong> Mesh networking over Bluetooth or Wi-Fi when infrastructure collapses. Sync devices in person to exchange trust codes.</li>
            <li><strong>Email:</strong> Treat PGP as archival privacy, not realtime confidentiality. Encrypt with <code>gpg --encrypt --sign</code> so recipients can verify authenticity.</li>
            <li><strong>Voice:</strong> Use end-to-end encrypted voice calls with ZRTP where possible. If you must use PSTN, assume adversaries record metadata.</li>
        </ul>
        
        <p><strong>Security Impact:</strong> Signal uses the Signal Protocol (double ratchet algorithm with perfect forward secrecy)—compromising one message doesn't reveal previous messages. Phone number linkage is a metadata risk but required for spam prevention. Session uses onion routing (3-hop like Tor) to hide IP addresses. Briar doesn't require internet: crucial during shutdowns or censorship. PGP email lacks forward secrecy: if your private key is compromised, all past messages are readable. PSTN (regular phone calls) has zero encryption and carriers log duration, parties, and location.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Signal setup with hardened settings
# Install Signal Desktop: https://signal.org/download/
# Or from terminal:

# Download Signal signing key
# -O- = output to stdout
# gpg --dearmor = convert ASCII to binary
wget -O- https://updates.signal.org/desktop/apt/keys.asc | gpg --dearmor > signal-desktop-keyring.gpg
# Expected output: Key downloaded and converted

# Install key to system keyrings
# tee = write to file (as sudo)
cat signal-desktop-keyring.gpg | sudo tee /usr/share/keyrings/signal-desktop-keyring.gpg > /dev/null
# Expected output: Key installed
# Why: Verify Signal packages are authentic

# Add Signal repository
# deb = Debian repository
# signed-by = use specific key to verify
# xenial = Ubuntu codename (works on all versions)
echo 'deb [arch=amd64 signed-by=/usr/share/keyrings/signal-desktop-keyring.gpg] https://updates.signal.org/desktop/apt xenial main' | sudo tee /etc/apt/sources.list.d/signal-xenial.list
# Expected output: Repository added

# Install Signal
sudo apt update && sudo apt install signal-desktop
# Expected output: Signal installed
# Why: Signal uses Signal Protocol (double ratchet, perfect forward secrecy)
# Security: End-to-end encrypted, compromising one message doesn't reveal previous
# Use when: Secure messaging with phone number (convenience vs anonymity trade-off)

# Enable registration lock (prevents SIM swap account takeover)
# Signal Settings > Account > Registration Lock > Enable
# Requires PIN to register phone number on new device
# Why: SIM swap attacks port your number to attacker's device
# Security: Even with your SIM, attacker needs PIN to access account
# Use when: Setting up Signal (do this immediately)

# Review linked devices monthly
# Settings > Linked Devices
# Remove any unrecognized devices immediately
# Why: Old/forgotten devices may be compromised
# Security: Attacker with old phone can read new messages
# Use when: Monthly security audit

# Enable disappearing messages by default
# Settings > Privacy > Disappearing Messages > Set default timer
# Why: Messages auto-delete after timer expires
# Security: Reduces data available during device seizure
# Use when: High-threat scenarios

# Verify safety numbers before sensitive conversations
# Open chat > Profile > View Safety Number
# Compare in person or via already-secure channel
# If numbers don't match: MITM attack or key change
# Why: Safety numbers are fingerprints of encryption keys
# Security: Matching numbers = you're talking to intended person
# Security: Mismatch = someone intercepting messages
# Use when: Before discussing sensitive topics

# Session (phone-number-free alternative)
# Download: https://getsession.org/download
# Or build from source: https://github.com/oxen-io/session-desktop

# Session IDs are long hex strings, not phone numbers
# Share session ID via QR code or secure channel
# Example: 05a1b2c3d4e5f6...
# Why: No phone number = no linkage to identity
# Security: Harder to correlate with real identity
# Use when: Need anonymity, not just privacy

# Briar (mesh/offline messaging)
# Install from F-Droid or: https://briarproject.org/download.html

# Install Briar desktop
sudo apt install briar-desktop
# Expected output: Package installed
# Why: Briar works without internet (Bluetooth, WiFi Direct, Tor)
# Security: Censorship-resistant, works during internet shutdowns
# Use when: Infrastructure unavailable or untrusted

# Add contacts in person via QR code or Bluetooth
# Settings > Add Contact > Show QR Code
# Or: Settings > Add Contact > Add Nearby Contact
# Why: In-person key exchange prevents MITM
# Security: No centralized server to compromise

# Briar works without internet:
# - Bluetooth (10m range)
# - WiFi Direct (100m range)
# - Tor (when internet available)
# Why: Multiple transport methods for resilience
# Use when: Organizing in hostile environments

# PGP email encryption (Thunderbird + Enigmail)
# Install GPG

# Install GnuPG and Thunderbird
# gnupg = GPG implementation
# thunderbird = email client
sudo apt install gnupg thunderbird
# Expected output: Packages installed
# Why: GPG encrypts email, Thunderbird provides interface

# Generate PGP key pair
# --full-generate-key = interactive key generation
gpg --full-generate-key
# Prompts:
# Select: RSA and RSA, 4096 bits, no expiration (or 2 years)
# Enter real name and email
# Expected output: Key pair generated
# Why: RSA 4096-bit provides strong encryption
# Security: Private key encrypts, public key decrypts (asymmetric crypto)
# Note: Consider expiration date (forces key renewal)

# Export public key for sharing
# --armor = ASCII format (email-safe)
# --export = export public key
gpg --armor --export your@email.com > pubkey.asc
# Expected output: Public key exported to file
# Why: Share public key so others can encrypt to you
# Security: Public key is safe to share (only decrypts messages)

# Import recipient's public key
# --import = add key to keyring
gpg --import recipient_pubkey.asc
# Expected output: Key imported
# Why: Need their public key to encrypt messages to them

# Encrypt and sign message
# echo = create message
# | = pipe to GPG
# --encrypt = encrypt message
# --sign = sign with your key (proves authenticity)
# --armor = ASCII output
# -r = recipient (their email/key ID)
echo "Secret message" | gpg --encrypt --sign --armor -r recipient@email.com > encrypted.asc
# Expected output: Encrypted message in ASCII armor
# Why: Encryption = only recipient can read
# Why: Signature = recipient knows it's from you
# Use when: Sending sensitive information via email

# Decrypt received message
# --decrypt = decrypt message
gpg --decrypt encrypted.asc
# Expected output: Prompts for passphrase, then shows plaintext
# Why: Your private key decrypts messages encrypted to you
# Security: Private key never leaves your machine

# Thunderbird auto-encryption setup
# Settings > End-to-End Encryption > Add Key
# Enable "Encrypt drafts" and "Sign non-encrypted messages"
# Why: Automates encryption/signing workflow
# Security: Drafts encrypted (protect against email server compromise)
# Use when: Regular secure email communication

# XMPP with OMEMO encryption (Conversations, Gajim)
# Install Gajim

# Install Gajim XMPP client
# gajim = XMPP client
# gajim-omemo = OMEMO encryption plugin
sudo apt install gajim gajim-omemo
# Expected output: Packages installed
# Why: XMPP is decentralized, OMEMO provides Signal-like encryption
# Security: End-to-end encrypted, forward secrecy

# Create account on privacy-focused server
# https://compliance.conversations.im/
# Recommended: conversations.im, disroot.org, wiuwiu.de
# Why: Choose server with strong privacy policy
# Security: Metadata still visible to server (who talks to whom, when)
# Use when: Need encrypted IM with decentralized infrastructure

# Enable OMEMO plugin
# Gajim > Plugins > OMEMO > Activate
# Expected output: Plugin activated
# Why: OMEMO is XMPP's Signal Protocol implementation

# Verify fingerprints before sensitive chat
# Right-click contact > OMEMO Fingerprints
# Compare via secure channel
# Why: Fingerprint verification prevents MITM
# Security: Matching fingerprints = talking to real contact
# Use when: Before sensitive discussions

# Jitsi Meet (encrypted video calls, self-hostable)
# Use instance: https://meet.jit.si/
# Or self-host: https://jitsi.github.io/handbook/

# Generate random room name
# 32-character random string for room ID
cat /dev/urandom | tr -dc 'a-z0-9' | fold -w 32 | head -n 1
# Expected output: Random room name (e.g., "x7k2m9p4q1zn...")
# Share via Signal/Session only
# Enable password protection and lobby mode
# Why: Random room name = hard to guess
# Security: Password + lobby prevents unauthorized joiners
# Use when: Need encrypted video conferencing</code></pre>
        
        <p><strong>Key Verification Discipline:</strong> Always verify safety numbers, fingerprints, or public keys out-of-band (in person, phone call, or previously-secured channel). A man-in-the-middle attack inserts attacker's keys between you and recipient. If you don't verify, you might be encrypting to the attacker's key instead of your intended recipient's key.</p>
        
        <p><strong>Metadata Minimization:</strong> Even with encrypted content, metadata leaks patterns. Use tools that route through Tor or onion networks (Session, Briar over Tor, OnionShare). Batch messages instead of responding immediately to obscure timing patterns. Use cover traffic or send dummy messages to mask communication frequency.</p>
        <h2>7. Cleaning Your Data (Metadata)</h2>
        <p>
            Metadata is the intel goldmine. Scrub files locally before they leave your control. Automate the process so routine tasks do not rely on memory.
        </p>
        
        <p><strong>Why This Matters:</strong> Files contain hidden data that betrays operational security. Photos include GPS coordinates, camera serial numbers, software versions, and timestamps. PDFs retain author names, edit history, hidden layers, and comments. Audio files embed electrical network frequency (ENF) that pinpoints recording location. Archives leak usernames, group IDs, and filesystem paths. This metadata survived whistleblower operations and led to arrests because the source didn't scrub files before release.</p>
        
        <h3>Precision Image Cleaning</h3>
        <pre data-lang="bash"><code class="language-bash"># Strip all metadata from image
# exiftool = comprehensive metadata manipulation tool
# -all= = delete all metadata tags
# --icc_profile:all= = exception: remove ICC color profile too
#   (ICC profiles can fingerprint your monitor/calibration)
exiftool -all= --icc_profile:all= photo.jpg
# Expected output: "1 image files updated"
# Creates backup: photo.jpg_original
# Why: Remove GPS, camera serial, software version, timestamps
# Security: GPS reveals exact location where photo taken
# Security: Camera serial links photos across pseudonyms
# Security: Software version (Photoshop, GIMP) reveals toolchain

# Verify metadata removed
# Lists all remaining metadata in image
exiftool photo.jpg
# Expected output: Minimal tags remaining (image dimensions, color space)
# Why: Confirm scrubbing actually worked
# Use when: Paranoid verification before sharing

# Batch process all images in directory
# find = search for files
# ./outbox = directory to process
# -type f = only files (not directories)
# -name '*.jpg' = match .jpg files
# -exec = run command on each found file
# -overwrite_original = don't create _original backups
find ./outbox -type f -name '*.jpg' -exec exiftool -overwrite_original -all= {} \;
# Expected output: "N image files updated"
# Why: Process entire directory automatically
# Security: Ensures no images leaked with metadata
# Use when: Preparing batch of files for publication</code></pre>
        <p>
            The <code>--icc_profile:all=</code> flag removes unique color profiles that can fingerprint your editor. Inspect the file a second time so you catch fields that regenerate.
        </p>
        
        <p><strong>Security Impact:</strong> GPS coordinates in photo EXIF reveal where you live, work, or met sources. Camera serial numbers link photos across pseudonyms. Software versions (Adobe Photoshop, GIMP) reveal your toolchain. ICC color profiles are unique per monitor calibration and can act as device fingerprints. Some cameras embed hidden metadata like lens serial numbers or even user-configured copyright strings with your real name.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Install exiftool
sudo apt install libimage-exiftool-perl

# Strip ALL metadata from single image
exiftool -all= --icc_profile:all= photo.jpg

# Verify removal
exiftool photo.jpg | grep -iE 'gps|camera|software|serial|author'

# Batch process entire directory (preserves originals with _original suffix)
exiftool -all= --icc_profile:all= -r -ext jpg -ext png ~/Pictures/to_share/

# Overwrite originals (no backup)
exiftool -all= --icc_profile:all= -overwrite_original -r ~/Pictures/to_share/

# Additional security: Re-save images to destroy hidden data
# This re-encodes and eliminates steganography or malformed chunks
for img in *.jpg; do
  convert "$img" -strip "cleaned_$img"
done

# Paranoid mode: Screenshot the image
# Opens in viewer, take screenshot, crop
# Eliminates all original metadata at cost of quality loss</code></pre>
        
        <h3>Documents and Audio</h3>
        <pre data-lang="bash"><code class="language-bash"># Clean PDF metadata in-place
# mat2 = Metadata Anonymisation Toolkit 2
# --inplace = overwrite original file (no backup)
mat2 --inplace report.pdf
# Expected output: "report.pdf: cleaned"
# Why: PDFs contain author names, organization, software version, edit history
# Security: Word docs track changes, comments, revision history
# Use when: Sharing documents that might contain identifying metadata

# Clean audio file
# Removes embedded metadata from WAV files
mat2 capture.wav
# Expected output: New file: capture.cleaned.wav
# Why: Audio contains ENF (electrical network frequency)
# Security: ENF geoloca​tes recording to specific power grid
# Use when: Sharing audio recordings</code></pre>
        <p>
            For high-stakes PDFs, consider rasterizing to destroy hidden layers, form fields, or revision history. Re-record audio so background hum does not expose location.
        </p>
        
        <p><strong>Security Impact:</strong> PDFs contain author names, organization names, revision history (showing edits/deletions), hidden layers with redacted content still readable, form field data, and embedded files. Word documents track changes and comments even after "accepting all changes." Audio files contain ENF (50/60 Hz hum from power grid) that geoloca​tes recordings to specific regions. Background sounds (sirens, languages, accents) reveal location and identity.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Install MAT2 (Metadata Anonymisation Toolkit 2)
sudo apt install mat2

# Clean PDF
mat2 --inplace sensitive_document.pdf

# Check what metadata would be removed (dry run)
mat2 --show document.pdf

# Clean audio file
mat2 --inplace recording.wav

# Paranoid PDF cleaning: Rasterize to destroy ALL structure
# Converts each page to image, eliminating hidden data
sudo apt install imagemagick
convert -density 300 document.pdf -quality 90 rasterized.pdf

# Verify no metadata remains
exiftool rasterized.pdf
pdfinfo rasterized.pdf

# Audio ENF removal (high-pass filter removes 50/60Hz grid hum)
ffmpeg -i input.wav -af "highpass=f=100, lowpass=f=15000" output.wav

# Or add noise to mask ENF
ffmpeg -i input.wav -af "anoisesrc=a=0.01:c=white" -map 0 -map 1 -c:v copy -shortest output.wav

# Document cleaning checklist:
# 1. Save as new file (don't edit original)
# 2. Remove comments and tracked changes
# 3. Run mat2 --inplace
# 4. Open in viewer, verify no hidden layers
# 5. For critical docs: Print to PDF to flatten everything</code></pre>
        
        <h3>Video Containers</h3>
        <pre data-lang="bash"><code class="language-bash"># Strip container metadata without re-encoding
# ffmpeg = multimedia processing framework
# -i = input file
# -map_metadata -1 = strip all metadata
# -c:v copy = copy video stream without re-encoding
# -c:a copy = copy audio stream without re-encoding
ffmpeg -i input.mp4 -map_metadata -1 -c:v copy -c:a copy output.mp4
# Expected output: "output.mp4" created without metadata
# Why: Fast processing, no quality loss
# Security: Removes GPS, camera model, recording date, creator name
# Limitation: Doesn't remove sensor noise patterns (camera fingerprint)
# Use when: Need quick metadata removal without re-encoding</code></pre>
        <p>
            Strip container metadata without touching the audio or video streams. When necessary, re-encode to blur EXIF-like camera signatures.
        </p>
        
        <p><strong>Security Impact:</strong> Video metadata includes camera make/model, GPS coordinates, recording date/time, software used for editing, and creator names. Some cameras embed unique sensor noise patterns (like a fingerprint) in every frame. Audio tracks may contain ENF. Unchanged video streams can be matched to originals via perceptual hashing even if re-uploaded.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Strip metadata only (fast, preserves quality)
ffmpeg -i input.mp4 -map_metadata -1 -c:v copy -c:a copy output.mp4

# Verify metadata removed
ffmpeg -i output.mp4 2>&1 | grep -i metadata
exiftool output.mp4

# Full re-encode to remove sensor noise patterns (slow, lossy)
# Also adds compression artifacts that obscure original source
ffmpeg -i input.mp4 -map_metadata -1 -c:v libx264 -crf 23 -preset medium -c:a aac -b:a 128k output.mp4

# Add noise to video to mask sensor patterns
ffmpeg -i input.mp4 -vf "noise=alls=10:allf=t" -map_metadata -1 -c:a copy output.mp4

# Remove audio entirely (if it contains identifying info)
ffmpeg -i input.mp4 -an -map_metadata -1 -c:v copy output.mp4

# Crop video to remove identifiable background elements
ffmpeg -i input.mp4 -vf "crop=1280:720:100:50" -map_metadata -1 output.mp4</code></pre>
        
        <h3>Archive Hygiene</h3>
        <pre data-lang="bash"><code class="language-bash"># Create sanitized archive
# tar = tape archive tool
# --owner=0 = set owner to root (UID 0)
# --group=0 = set group to root (GID 0)
# --numeric-owner = use numeric IDs, not names
# --mtime='UTC 2000-01-01' = set all file timestamps to Jan 1 2000
# -czf = create, gzip compress, file
# clean_archive.tar.gz = output file
# ./files = directory to archive
tar --owner=0 --group=0 --numeric-owner --mtime='UTC 2000-01-01' -czf clean_archive.tar.gz ./files
# Expected output: Archive created with sanitized metadata
# Why: Archives store file ownership (username) and timestamps
# Security: Username reveals your system account name
# Security: Timestamps reveal timezone and workflow patterns
# Use when: Creating reproducible, privacy-respecting archives</code></pre>
        <p>
            Reset ownership and timestamps so archives do not leak system details. Keep release archives in read-only storage so hashes remain stable.
        </p>
        
        <p><strong>Security Impact:</strong> Tar archives store file ownership (username and group), timestamps (creation/modification times), and permissions. These reveal your system username, timezone, and workflow patterns. Forensic analysts extract this to profile creators. Changing file contents after distribution breaks cryptographic hashes, making integrity verification impossible.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Create archive with sanitized metadata
tar --owner=0 --group=0 --numeric-owner --mtime='UTC 2000-01-01' -czf release.tar.gz ./files/

# Verify no identifying info
tar -tvf release.tar.gz | head
# Should show: owner=0, group=0, date=2000-01-01

# Alternative: Use reproducible-builds tools
# Install: pip3 install repro-get
strip-nondeterminism release.tar.gz

# Zip archives (similar sanitization)
touch -t 200001010000 file1.txt file2.txt
zip -X release.zip file1.txt file2.txt

# Mark archive read-only to prevent accidental modification
chmod 444 release.tar.gz

# Generate hash for integrity checking
sha256sum release.tar.gz > release.tar.gz.sha256
gpg --clearsign release.tar.gz.sha256

# Users verify:
sha256sum -c release.tar.gz.sha256
gpg --verify release.tar.gz.sha256</code></pre>
        
        <h3>Chain of Custody</h3>
        <pre data-lang="bash"><code class="language-bash"># Calculate hash of original file
# sha256sum = calculate SHA-256 cryptographic hash
sha256sum original.pdf
# Expected output: 64-character hex hash
# Why: Hash is cryptographic fingerprint of file
# Security: Any change to file produces completely different hash
# Use when: Establishing provenance for evidence

# process the file (clean metadata, etc.)

# Calculate hash after processing
sha256sum original.cleaned.pdf
# Expected output: Different hash (file contents changed)
# Why: Document that processing occurred
# Security: Proves when and how file was modified
# Use when: Maintaining evidence integrity in legal/journalistic contexts</code></pre>
        <p>
            Record both hashes whenever evidence integrity matters. Store the log in append-only storage and countersign with a trusted witness.
        </p>
        
        <p><strong>Security Impact:</strong> In legal or journalistic contexts, proving files weren't tampered with is critical. Cryptographic hashes provide mathematical proof of integrity. Append-only logs (like Git or blockchain) prevent retroactive modification of custody records. Witness signatures provide non-repudiation.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Document chain of custody
echo "$(date -Iseconds) - Original file received" >> custody.log
sha256sum source_document.pdf >> custody.log

# Process file
mat2 --inplace source_document.pdf

# Record post-processing
echo "$(date -Iseconds) - Metadata removed with mat2" >> custody.log
sha256sum source_document.pdf >> custody.log

# GPG sign the custody log
gpg --clearsign custody.log

# Witness signature (from trusted party)
gpg --local-user witness@email.com --clearsign custody.log.asc

# Store in Git for tamper-evident versioning
git init evidence_repo
git add custody.log* source_document.pdf
git commit -m "Initial custody: $(date -Iseconds)"
# Each subsequent change is tracked and signed

# Or use OpenTimestamps for blockchain proof
# Install: pip3 install opentimestamps-client
ots stamp custody.log
# Creates .ots file with Bitcoin blockchain timestamp
# Proves file existed at specific time</code></pre>

        <h2>8. Encryption and Protecting Files</h2>
        <p>
            Encryption must exist both at rest and in transit, with recovery plans for corrupted headers or forced disclosure laws.
        </p>
        
        <p><strong>Why This Matters:</strong> Unencrypted data is readable by anyone with physical or remote access: law enforcement during searches, thieves with stolen devices, border agents, malicious insiders, or hackers. Full disk encryption (FDE) protects against offline attacks where attacker boots another OS to bypass file permissions. File-level encryption protects specific sensitive data even if FDE is unlocked. In jurisdictions with key disclosure laws (UK RIPA, India IT Act), plausible deniability through hidden volumes can protect you from forced decryption orders.</p>
        
        <h3>Full Disk Encryption</h3>
        <ul>
            <li>Use LUKS2 on Linux and back up the header with <code>cryptsetup luksHeaderBackup</code>. Store the header offline and test restoration.</li>
            <li>Enable TPM-bound auto unlock only when paired with a hardware key so the boot flow fails if tampered.</li>
            <li>Consider configuring a nuke passphrase that overwrites keyslots when coerced.</li>
        </ul>
        
        <p><strong>Security Impact:</strong> LUKS encrypts entire partitions with AES-256 (128-bit security level against quantum attacks via Grover's algorithm). Header contains encryption metadata: if corrupted, data is permanently lost. TPM binding ensures decryption only succeeds on unchanged firmware (prevents Evil Maid attacks). Nuke passwords trigger keyslot erasure, rendering data unrecoverable (useful under duress in jurisdictions without obstruction laws).</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Backup LUKS header (CRITICAL for recovery)
# cryptsetup = LUKS management tool
# luksHeaderBackup = save header to file
# /dev/nvme0n1p3 = your encrypted partition (adjust to your system)
# --header-backup-file = where to save header
sudo cryptsetup luksHeaderBackup /dev/nvme0n1p3 --header-backup-file luks_header_backup.img
# Expected output: "Header backup successful"
# Why: Header contains encryption metadata (without it, data is unrecoverable)
# Security: Corrupted header = permanent data loss
# Use when: Immediately after creating LUKS partition

# Encrypt and store backup securely
# --encrypt = GPG encrypt file
# --recipient = your GPG key
gpg --encrypt --recipient your@email.com luks_header_backup.img
# Expected output: luks_header_backup.img.gpg created
# Store on offline USB in safe
# Why: Encrypted backup prevents unauthorized decryption
# Security: Header backup can decrypt drive if you have passphrase

# Restore header if corrupted
# luksHeaderRestore = restore header from backup
sudo cryptsetup luksHeaderRestore /dev/nvme0n1p3 --header-backup-file luks_header_backup.img
# Expected output: "Header restored successfully"
# Why: Recovers encrypted data after header corruption
# Use when: Boot fails with "no key available" or header damage

# Add nuke password (requires cryptsetup-nuke-password package)
# WARNING: Typing nuke password destroys all keyslots permanently
sudo apt install cryptsetup-nuke-password
# During boot, typing nuke password destroys all keyslots
# WARNING: Makes data permanently unrecoverable
# Why: Emergency data destruction under duress
# Security: Coerced to decrypt? Type nuke password instead
# Legal: Check local laws (destroying evidence may be crime)

# TPM-bound auto-unlock (already covered in Section 3)
# Binds encryption key to firmware state
sudo systemd-cryptenroll --tpm2-device=auto --tpm2-pcrs=0+7 /dev/nvme0n1p3

# Add recovery passphrase (different from main password)
# luksAddKey = add additional keyslot
sudo cryptsetup luksAddKey /dev/nvme0n1p3
# Expected output: Prompts for existing password, then new password
# Why: Backup password in case primary forgotten
# Store recovery passphrase in safe, not on computer
# Security: Each keyslot can decrypt drive independently

# List keyslots
# luksDump = show LUKS header information
sudo cryptsetup luksDump /dev/nvme0n1p3
# Expected output: Shows keyslots 0-7, which are active
# Why: See how many passwords/keys enrolled

# Remove compromised keyslot
# luksKillSlot = permanently delete keyslot
# 1 = keyslot number to remove
sudo cryptsetup luksKillSlot /dev/nvme0n1p3 1
# Expected output: "Keyslot 1 removed"
# Why: Revoke compromised password
# Security: Old password no longer works
# Use when: Suspect password leaked or person left team

# Verify LUKS encryption is active
# status = show encryption status
# /dev/mapper/cryptroot = decrypted device mapper name
sudo cryptsetup status /dev/mapper/cryptroot
# Expected output:
#   type: LUKS2
#   cipher: aes-xts-plain64
#   keysize: 512 bits
# Why: Confirm encryption is actually active
# Use when: Verifying system security after setup

# Re-encrypt with new key (if main password compromised)
# luksChangeKey = change passphrase for keyslot
sudo cryptsetup luksChangeKey /dev/nvme0n1p3
# Expected output: Prompts for old password, then new password
# Why: Rotate password after potential compromise
# Security: Old password stops working immediately
# Use when: Password exposed or during regular key rotation</code></pre>
        
        <h3>Plausible Deniability</h3>
        <p>
            VeraCrypt hidden volumes provide a decoy layer that withstands legal pressure where key disclosure is enforced. Keep decoy data convincing and update timestamps so it looks actively used.
        </p>
        
        <p><strong>Security Impact:</strong> Hidden volumes exist within outer volumes. You reveal outer password under coercion, showing decoy data (taxes, family photos). Hidden volume remains mathematically indistinguishable from random data. Without password, attacker cannot prove hidden volume exists. This defeats compelled decryption laws but ONLY if decoy is convincing and regularly updated. Unused decoy (old timestamps, few files) looks suspicious.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Install VeraCrypt
# add-apt-repository = add PPA (Personal Package Archive)
# ppa:unit193/encryption = VeraCrypt repository
sudo add-apt-repository ppa:unit193/encryption
sudo apt update && sudo apt install veracrypt
# Expected output: VeraCrypt installed
# Why: VeraCrypt provides plausible deniability via hidden volumes
# Security: Hidden volume mathematically indistinguishable from random data

# Create standard volume (outer volume)
# veracrypt = encryption tool
# --text = command-line mode
# --create = create new volume
# /home/user/container.vc = file to create
# --size=10G = 10 gigabytes
# --volume-type=normal = standard (not hidden) volume
# --encryption=AES = use AES-256 cipher
# --hash=SHA-512 = key derivation hash
# --filesystem=ext4 = format as Linux ext4
# --pim=0 = no PIM (personal iterations multiplier)
# --keyfiles= = no keyfiles (password only)
# --random-source=/dev/urandom = entropy source
veracrypt --text --create /home/user/container.vc \
  --size=10G \
  --volume-type=normal \
  --encryption=AES \
  --hash=SHA-512 \
  --filesystem=ext4 \
  --pim=0 \
  --keyfiles= \
  --random-source=/dev/urandom
# Expected output: Prompts for password, creates container
# Why: Outer volume holds decoy data
# Security: When coerced, reveal outer password to show "nothing to hide"

# Mount outer volume and add decoy data
# veracrypt --text = command-line mount
# /mnt/decoy = mount point
veracrypt --text /home/user/container.vc /mnt/decoy
# Copy decoy files (make it look realistic)
cp -r ~/Documents/Taxes /mnt/decoy/
cp -r ~/Pictures/Family /mnt/decoy/
# Make it look realistic: work documents, photos, etc.
# Why: Convincing decoy prevents suspicion
# Security: Empty or obviously fake decoy reveals hidden volume existence

# Create hidden volume within outer volume
# --volume-type=hidden = create hidden volume
# --size=5G = 5GB (must be smaller than outer volume free space)
veracrypt --text --create /home/user/container.vc \
  --size=5G \
  --volume-type=hidden \
  --encryption=AES \
  --hash=SHA-512 \
  --filesystem=ext4
# Expected output: Prompts for outer password, then hidden password
# Why: Hidden volume exists in outer volume's "free space"
# Security: Without hidden password, impossible to prove hidden volume exists

# Mount hidden volume (use hidden password)
# When prompted, enter hidden password (not outer password)
veracrypt --text /home/user/container.vc /mnt/hidden
# Copy sensitive data here
# Why: Real secrets stored in hidden volume
# Security: Only accessible with hidden password

# CRITICAL: Protect hidden volume from damage
# Always mount with --protect-hidden option
# --protect-hidden = ask for hidden password, prevent overwriting
veracrypt --text --protect-hidden /home/user/container.vc /mnt/decoy
# Expected output: Prompts for outer password, then hidden password
# Why: Writing to outer volume can corrupt hidden volume
# Security: VeraCrypt checks hidden volume boundaries, prevents damage
# Use when: Accessing outer volume after hidden volume created

# Update decoy data monthly to maintain plausibility
# Open files, modify timestamps, add new content
# touch = update file modification time
touch /mnt/decoy/Taxes/2024_receipts.pdf
echo "New budget notes" >> /mnt/decoy/budget.txt
# Why: Stale data (old timestamps) looks suspicious
# Security: Actively-used decoy appears legitimate

# Under coercion: Provide outer password only
# Authorities see decoy data, cannot prove hidden volume exists
# Why: Plausible deniability protects against forced decryption
# Legal: Check jurisdiction (UK RIPA can prosecute for not revealing "all" keys)</code></pre>
        
        <h3>File-Level Encryption</h3>
        <p>
            For individual sensitive files, GPG provides authenticated encryption. Encrypt files before cloud sync so providers see only ciphertext.
        </p>
        
        <p><strong>Security Impact:</strong> File-level encryption protects specific files even when disk is unlocked and system running. Cloud providers, backups, and compromised accounts cannot read encrypted files without decryption key. GPG uses hybrid encryption: symmetric AES-256 for data, RSA/ECC for key wrapping. Authenticated encryption prevents tampering.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Encrypt single file to yourself
# gpg = GNU Privacy Guard
# --encrypt = encrypt file
# --recipient = your GPG key email or ID
gpg --encrypt --recipient your@email.com sensitive_document.pdf
# Expected output: Creates: sensitive_document.pdf.gpg
# Why: File-level encryption protects specific files
# Security: Cloud providers can't read encrypted files
# Use when: Storing sensitive files in cloud or backups

# Decrypt
# --decrypt = decrypt file
# > = redirect output to file
gpg --decrypt sensitive_document.pdf.gpg > sensitive_document.pdf
# Expected output: Prompts for passphrase, creates plaintext file
# Why: Recover original file from encrypted version

# Encrypt with symmetric password (no key needed)
# --symmetric = password-based encryption (not public-key)
# --cipher-algo AES256 = use AES-256 cipher
gpg --symmetric --cipher-algo AES256 file.txt
# Expected output: Prompts for password twice, creates: file.txt.gpg
# Why: Simpler than public-key crypto (no key management)
# Security: Strong password required (passphrase, not "password123")
# Use when: Encrypting for yourself or sharing password out-of-band

# Decrypt symmetric
# Same command as asymmetric, GPG auto-detects
gpg --decrypt file.txt.gpg > file.txt
# Expected output: Prompts for password, decrypts file

# Encrypt entire directory
# tar czf - = create gzipped tar archive, output to stdout
# | = pipe to GPG
# > backup.tar.gz.gpg = save encrypted archive
tar czf - ~/Documents/Sensitive/ | gpg --encrypt --recipient your@email.com > backup.tar.gz.gpg
# Expected output: Encrypted archive created
# Why: Compress and encrypt multiple files at once
# Use when: Backing up sensitive directories

# Decrypt and extract
# gpg --decrypt = decrypt archive
# | tar xzf - = extract gzipped tar from stdin
gpg --decrypt backup.tar.gz.gpg | tar xzf -
# Expected output: Files extracted to current directory
# Why: One command to decrypt and extract

# Automated encrypted backups to cloud
#!/bin/bash
# Backup script for automated encrypted cloud backups
BACKUP_DIR="/home/user/Documents"
BACKUP_FILE="backup-$(date +%Y%m%d).tar.gz.gpg"
# Create compressed encrypted backup
tar czf - "$BACKUP_DIR" | gpg --encrypt --recipient your@email.com > "$BACKUP_FILE"
# Upload to cloud (rclone = rsync for cloud storage)
rclone copy "$BACKUP_FILE" remote:encrypted_backups/
# Securely delete local copy
# shred = overwrite file before deletion
# -vfz = verbose, force, zero-fill
shred -vfz "$BACKUP_FILE"
# Why: Automate secure backups without manual intervention
# Security: Cloud provider sees only encrypted data
# Use when: Regular backups to untrusted cloud storage

# Verify encryption (file should be unreadable)
# file = identify file type
file backup.tar.gz.gpg
# Expected output: "GPG encrypted data" or "PGP encrypted"
# Why: Confirm file is actually encrypted

# Try reading encrypted file (should be gibberish)
# strings = extract printable strings from binary
strings backup.tar.gz.gpg | head
# Expected output: Random binary garbage
# Why: Verify no plaintext leaked
# Security: If you see readable text, encryption failed</code></pre>
        <h3>GPG for Files and Archives</h3>
        <ul>
            <li>Symmetric: <code>gpg --symmetric --cipher-algo AES256 file.txt</code> and send the password over a separate channel.</li>
            <li>Asymmetric: <code>gpg --encrypt --recipient user@example.com file.txt</code> so only the recipient key can decrypt.</li>
            <li>Batch encryption: <code>tar -czf - secrets | gpg --encrypt --recipient user@example.com &gt; bundle.tgz.gpg</code>.</li>
        </ul>
        <p>
            Rotate keys annually and publish revocation certificates in multiple locations. For legal travel, carry clean keys and store sensitive ones inside a secure drop.</p>

        <h2>9. Network Security and Browsing</h2>
        <p>
            Assume your ISP sells your traffic patterns. Take back DNS, watch egress, and understand the trust trade-offs between Tor and VPNs.
        </p>
        
        <p><strong>Why This Matters:</strong> Your ISP logs every DNS query (revealing every website you visit), sells browsing data to advertisers, and cooperates with law enforcement without warrants (in many jurisdictions). DNS queries are typically unencrypted, readable by anyone on network path. Applications phone home with telemetry without your consent. Malware creates outbound connections to command & control servers. Tor provides anonymity but is slow; VPNs are faster but require trusting the provider. Network segmentation contains compromised devices.</p>
        
        <ul>
            <li>Run Unbound as a recursive resolver and pair it with Pi-hole or AdGuard Home to block trackers at the DNS layer. Enable DNS over TLS so upstream queries are encrypted.</li>
            <li>Deploy OpenSnitch or Little Snitch to monitor outbound connections per process. Alert on unexpected telemetry domains.</li>
            <li>Use Tor when anonymity outweighs latency. Prefer bridges in hostile networks. Use multi-hop commercial VPNs only when you trust their jurisdiction and logging claims.</li>
            <li>Segment networks with VLANs: isolate IoT gear, guest Wi-Fi, and workstations. Use firewall rules to limit lateral movement.</li>
            <li>Enable WPA3 on wireless networks and rotate secrets after guests connect.</li>
        </ul>
        <p>
            Capture baseline traffic samples so you can detect anomalies. Store firewall configs in version control for quick rollback.
        </p>
        
        <p><strong>Security Impact:</strong> Unbound recursively resolves DNS from root servers, bypassing ISP DNS entirely. Pi-hole blocks tracking/ads at DNS level (works for all devices on network, including phones/IoT). DNS over TLS encrypts queries to upstream resolvers, hiding them from ISPs. OpenSnitch is application firewall: catches malware phoning home, blocks telemetry. Tor routes through 3 random relays, hiding your IP from destination and hiding destination from ISP. VPNs centralize trust in one provider. VLANs prevent compromised IoT device from scanning your workstation. WPA3 uses individual encryption per client (harder to crack with packet capture).</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Install Pi-hole for network-wide ad/tracker blocking
curl -sSL https://install.pi-hole.net | bash
# During install, set DNS to 127.0.0.1 (use Pi-hole itself)
# Set router DHCP to advertise Pi-hole IP as DNS server

# Configure DNS over TLS (DoT) in Pi-hole
# Settings > DNS > Upstream DNS Servers
# Enable: Cloudflare DNS over TLS (1.1.1.1#853)
# Or: Quad9 DNS over TLS (9.9.9.9#853)

# Add blocklists to Pi-hole
# Tools > Update Gravity
# Add custom lists:
# https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts
# https://someonewhocares.org/hosts/hosts

# Install Unbound as recursive DNS resolver (pairs with Pi-hole)
sudo apt install unbound
sudo tee /etc/unbound/unbound.conf.d/pi-hole.conf << 'EOF'
server:
    interface: 127.0.0.1
    port: 5335
    do-ip6: no
    do-udp: yes
    do-tcp: yes
    root-hints: "/var/lib/unbound/root.hints"
    hide-identity: yes
    hide-version: yes
    harden-glue: yes
    harden-dnssec-stripped: yes
    use-caps-for-id: no
    prefetch: yes
    num-threads: 2
EOF

wget https://www.internic.net/domain/named.root -O /var/lib/unbound/root.hints
sudo systemctl restart unbound

# Configure Pi-hole to use Unbound
# Settings > DNS > Upstream DNS > Custom: 127.0.0.1#5335

# Install OpenSnitch (application firewall)
# Download from: https://github.com/evilsocket/opensnitch/releases
# Debian/Ubuntu:
wget https://github.com/evilsocket/opensnitch/releases/download/v1.6.0/opensnitch_1.6.0-1_amd64.deb
wget https://github.com/evilsocket/opensnitch/releases/download/v1.6.0/python3-opensnitch-ui_1.6.0-1_all.deb
sudo apt install ./opensnitch_1.6.0-1_amd64.deb ./python3-opensnitch-ui_1.6.0-1_all.deb

# Start OpenSnitch
sudo systemctl enable --now opensnitch
opensnitch-ui

# Configure rules (GUI prompts on first connection)
# Block telemetry domains: telemetry.microsoft.com, etc.
# Allow only essential connections

# Tor setup for anonymity
sudo apt install tor
sudo systemctl enable --now tor

# Configure Tor Browser to use system Tor
# Or use torify with any application
torify curl https://check.torproject.org/

# Tor with bridges (for censored networks)
# Get bridges: https://bridges.torproject.org/
# Edit /etc/tor/torrc:
UseBridges 1
Bridge obfs4 [IP:PORT] [FINGERPRINT] ...
Bridge obfs4 [IP:PORT] [FINGERPRINT] ...

# Restart Tor
sudo systemctl restart tor

# VPN setup (Mullvad example - no-logging policy)
# Download: https://mullvad.net/en/download/
sudo apt install ./mullvad-vpn_*.deb

# Enable killswitch (blocks internet if VPN drops)
mullvad lan set allow
mullvad auto-connect set on
mullvad lockdown-mode set on

# Multi-hop VPN (routes through 2+ servers)
# Requires provider support (Mullvad, IVPN, ProtonVPN)

# Network segmentation with VLANs (requires managed switch)
# Create VLANs on router/switch:
# VLAN 10: Trusted (workstations)
# VLAN 20: IoT (smart devices, cameras)
# VLAN 30: Guest WiFi

# Firewall rules (iptables example):
# Allow IoT to internet only, block access to other VLANs
sudo iptables -A FORWARD -i eth0.20 -o eth0.10 -j DROP
sudo iptables -A FORWARD -i eth0.20 -o eth0 -j ACCEPT

# WiFi WPA3 setup (requires router support)
# Router web interface > Wireless Security
# Set: WPA3-Personal or WPA3-SAE
# Set strong passphrase (20+ characters)

# Rotate WiFi password after guests
# Change passphrase, reconnect trusted devices

# Monitor network traffic for anomalies
# Install ntopng
sudo apt install ntopng
sudo systemctl enable --now ntopng
# Access: http://localhost:3000

# Capture baseline traffic
sudo tcpdump -i eth0 -w baseline.pcap -c 10000
# Analyze with Wireshark for normal patterns

# Store firewall config in Git
sudo iptables-save > /etc/iptables/rules.v4
cd /etc/iptables
git init
git add rules.v4
git commit -m "Baseline firewall rules"</code></pre>

        <h2>10. Using Virtual Machines for Safety</h2>
        <p>
            Virtualization is your disposable sandbox. Never detonate suspicious files on the host.
        </p>
        
        <p><strong>Why This Matters:</strong> Suspicious files, untrusted software, and malware analysis require isolation. Running them on your host OS risks persistent compromise. Virtual machines provide containment: if malware escapes, snapshots let you revert to clean state instantly. Hypervisor vulnerabilities are rare but possible, so Qubes OS uses Xen's strong isolation. Disposable VMs prevent forensic artifacts from accumulating. Shared folders and clipboard between host/guest are attack vectors.</p>
        
        <ul>
            <li>Maintain a dirty analysis VM with snapshots you can revert instantly. Disable shared clipboard and drag-and-drop.</li>
            <li>Adopt Qubes OS for strict isolation of networking, USB devices, and disposable workspaces. Use <code>qvm-prefs</code> to deny networking to untrusted domains.</li>
            <li>Use immutable base images for daily browsing and rebuild them from code so implants cannot persist across updates.</li>
            <li>Automate snapshot expiration. Old snapshots contain secrets. Remove them on a schedule.</li>
        </ul>
        <p>
            When malware analysis is complete, export findings through sanitized channels and destroy the VM. Log hash values of samples for future reference.
        </p>
        
        <p><strong>Security Impact:</strong> VM isolation means guest malware cannot directly access host files or hardware (unless exploit exists). Snapshots are instant rollback: any changes (malware persistence, registry modifications) are wiped. Qubes OS enforces security through isolation: separate VMs for work, personal, banking, untrusted. If work VM compromised, banking VM remains safe. Shared clipboard can leak data or allow command injection. Immutable images prevent persistent malware: each reboot starts from known-good state.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Install KVM/QEMU for VMs
sudo apt install qemu-kvm libvirt-daemon-system libvirt-clients bridge-utils virt-manager

# Add user to libvirt group
sudo usermod -aG libvirt $USER

# Create malware analysis VM (isolated, no network)
virt-install \
  --name malware-lab \
  --ram 4096 \
  --vcpus 2 \
  --disk path=/var/lib/libvirt/images/malware-lab.qcow2,size=20 \
  --os-variant ubuntu22.04 \
  --network none \
  --graphics spice \
  --cdrom /path/to/ubuntu.iso

# Disable shared folders and clipboard in VM settings
virsh edit malware-lab
# Remove <channel> and <filesystem> sections

# Take snapshot before analysis
virsh snapshot-create-as malware-lab clean_slate "Pre-analysis clean state"

# List snapshots
virsh snapshot-list malware-lab

# Revert to clean snapshot after analysis
virsh snapshot-revert malware-lab clean_slate

# Delete VM entirely after analysis
virsh destroy malware-lab
virsh undefine malware-lab --remove-all-storage

# Qubes OS for daily use (requires installation)
# Download: https://www.qubes-os.org/downloads/

# Create new Qubes VM (after Qubes installation)
qvm-create --template debian-12 --label red untrusted
qvm-create --template debian-12 --label green banking
qvm-create --template whonix-gw-17 --label purple anon

# Disable networking for offline VM
qvm-prefs untrusted netvm ""

# Set disposable template (destroys VM on shutdown)
qvm-create --template fedora-38 --label red --class DispVM disp-template
qvm-prefs disp-template default_dispvm disp-template

# Launch disposable VM
qvm-run --dispvm disp-template firefox

# Transfer files safely (copy from untrusted to trusted)
qvm-copy-to-vm trusted-vault file.txt
# Requires user confirmation in destination VM

# Immutable VM with overlayfs (changes discarded on reboot)
# Create base image
qemu-img create -f qcow2 base.qcow2 20G

# Create overlay (writes go here, base remains unchanged)
qemu-img create -f qcow2 -b base.qcow2 overlay.qcow2

# Run VM with overlay
qemu-system-x86_64 -hda overlay.qcow2 -m 2G

# Discard overlay after use (reset to clean state)
rm overlay.qcow2
qemu-img create -f qcow2 -b base.qcow2 overlay.qcow2

# Automate snapshot cleanup (delete snapshots older than 7 days)
#!/bin/bash
for VM in $(virsh list --all --name); do
  for SNAPSHOT in $(virsh snapshot-list "$VM" --name); do
    CREATED=$(virsh snapshot-info "$VM" "$SNAPSHOT" | grep "Creation Time" | cut -d: -f2-)
    AGE_DAYS=$(( ($(date +%s) - $(date -d "$CREATED" +%s)) / 86400 ))
    if [ $AGE_DAYS -gt 7 ]; then
      echo "Deleting old snapshot: $VM / $SNAPSHOT"
      virsh snapshot-delete "$VM" "$SNAPSHOT"
    fi
  done
done

# Log malware sample hashes
sha256sum malware_sample.exe >> ~/analysis_log.txt
echo "Analysis date: $(date)" >> ~/analysis_log.txt
# Export findings via sanitized channel (encrypted email, air-gap transfer)</code></pre>

        <h2>11. Physical Security</h2>
        <p>
            Physical tampering buys adversaries time. Make intrusion obvious and deny them the ability to harvest secrets from RAM.
        </p>
        
        <p><strong>Why This Matters:</strong> Physical access defeats most security. An attacker with 5 minutes alone with your device can install hardware keyloggers, clone drives, flash modified firmware, or perform cold boot attacks to extract encryption keys from RAM. Evil Maid attacks modify bootloaders to capture passwords. Border agents have legal authority to seize and image devices. Hotel rooms, airport security areas, and repair shops are high-risk environments. Tamper evidence detects intrusion; physical protections prevent or delay it.</p>
        
        <ul>
            <li>Photograph glitter nail polish on screws as a tamper indicator. Compare photos after travel.</li>
            <li>Use the hair-in-the-seam or ultra-thin tape trick when leaving laptops unattended. If the seal breaks, treat the device as compromised.</li>
            <li>Power down fully to defeat cold boot attacks. Never rely on sleep. Remove batteries where practical.</li>
            <li>Carry hardware-encrypted drives such as IronKey or Apricorn Aegis with self-destruct thresholds. Test the zeroization feature annually.</li>
            <li>Store primary devices in Faraday bags when crossing hostile borders to prevent remote wake or baseband attacks.</li>
        </ul>
        
        <p><strong>Security Impact:</strong> Cold boot attacks exploit RAM remanence—DRAM retains data for seconds/minutes after power loss. Spraying RAM with freeze spray extends retention to hours. Keys are extracted via DMA or memory imaging. Full shutdown clears RAM. Sleep mode keeps RAM powered, vulnerable. Glitter polish creates unique, impossible-to-replicate patterns: any tampering is visible. Hardware keyloggers (inline USB devices or PCIe implants) capture all keystrokes including encryption passwords. Faraday bags block RF signals, preventing remote access to cellular/WiFi radios and baseband processors.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Tamper-evident seals with glitter nail polish
# 1. Apply clear coat with dense glitter over screws
# 2. Take high-resolution macro photos (10+ megapixels)
# 3. Store photos in encrypted container with hash

# Photo documentation
convert photo1.jpg photo2.jpg photo3.jpg -append tamper_seal_baseline.jpg
sha256sum tamper_seal_baseline.jpg > seal_hash.txt
gpg --encrypt --recipient your@email.com tamper_seal_baseline.jpg

# After travel, compare photos pixel-by-pixel
# Any difference indicates tampering

# Hair-in-the-seam trick
# 1. Place single hair across laptop hinge/seam
# 2. Close lid, note exact hair position
# 3. Photograph hair position
# 4. On return, check if hair moved or missing

# Ultra-thin tape (forensic evidence tape)
# Apply across seams, photograph serial number
# Removal leaves "VOID" pattern or tears

# Force full shutdown (never sleep)
# Disable sleep on lid close
gsettings set org.gnome.settings-daemon.plugins.power lid-close-ac-action 'nothing'
gsettings set org.gnome.settings-daemon.plugins.power lid-close-battery-action 'nothing'

# Always shutdown, never suspend
sudo systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target

# Verify RAM cleared after shutdown
# Boot to live USB, attempt memory forensics
# Should find no readable data

# Hardware encrypted USB drives (IronKey, Apricorn Aegis)
# These have onboard crypto chips, PIN entry, self-destruct after N failed attempts
# Purchase from trusted vendor (not Amazon/eBay - risk of interdiction)

# Test self-destruct annually
# Enter wrong PIN 9 times (if threshold is 10)
# Verify data still accessible
# On 10th wrong PIN, verify drive completely wiped

# Faraday bag usage (blocks all RF: cellular, WiFi, Bluetooth, GPS, NFC)
# Purchase military-grade bags (Mission Darkness, EDEC)
# Test effectiveness:
echo "Testing Faraday bag..."
# Put phone in bag
# Call phone from another device
# Should go straight to voicemail (no signal)

# Check bag seal integrity
# Place activated RF transmitter in bag
# Use spectrum analyzer or RF detector outside bag
# Should detect no signal

# Border crossing protocol
# 1. Shutdown devices fully (remove battery if possible)
# 2. Place in Faraday bag
# 3. Store in carryon (maintain visual contact)
# 4. If forced to unlock: use decoy profile/account
# 5. After crossing: boot from trusted live USB
# 6. Check firmware hashes against baseline
# 7. Inspect hardware for physical tampering

# Check for hardware keyloggers
lsusb -v | grep -i keyboard
# Compare to baseline, look for unexpected devices

# Open case, inspect USB headers on motherboard
# Look for inline devices between keyboard connector and board

# Wipe RAM on shutdown (kernel parameter)
# Edit /etc/default/grub:
GRUB_CMDLINE_LINUX="page_poison=1"
sudo update-grub

# Or enable memory zeroing module
echo "kernel.kptr_restrict = 2" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p</code></pre>

        <h2>12. Financial Privacy</h2>
        <p>
            Transactions reveal the map of your life. Separate sensitive purchases from identifiable financial trails.
        </p>
        
        <p><strong>Why This Matters:</strong> Financial records create a detailed profile of your life: where you shop, what you believe (donations), who you associate with (Venmo feeds), your health (pharmacy purchases), travel patterns (gas/hotels), and interests. Banks share data with law enforcement without warrants via subpoenas. Credit cards are trivially traceable. Bitcoin's blockchain is public and permanent: every transaction is visible forever. Chain analysis firms (Chainalysis, Elliptic) trace BTC to exchanges where KYC links it to real identity. Cash and Monero provide actual financial privacy.</p>
        
        <ul>
            <li>Build a routine cash reserve and spend from that pool for sensitive acquisitions. Make withdrawals during normal banking hours to stay inconspicuous.</li>
            <li>Understand that Bitcoin is traceable. Monero behaves like digital cash through ring signatures and stealth addresses. Mixers rarely hold up against motivated blockchain analysis.</li>
            <li>Use privacy-preserving prepaid cards acquired with cash when online merchants will not accept cryptocurrency.</li>
            <li>Distribute withdrawals over time to avoid anomalous spikes. Track expenses in a local ledger that is encrypted and air gapped.</li>
            <li>Redact shipping metadata by using lockers or authorized pickup locations that do not require government ID.</li>
        </ul>
        
        <p><strong>Security Impact:</strong> Cash leaves no digital trail. Large withdrawals ($5k+) trigger Currency Transaction Reports (CTRs). Structuring (splitting to avoid CTRs) is illegal. Bitcoin's UTXO model links inputs/outputs, revealing wallets and flows. Monero uses ring signatures (your transaction hidden among 15 others), stealth addresses (one-time addresses per transaction), and RingCT (hides amounts). Mixers/coinjoin improve Bitcoin privacy but are detectable and sometimes blacklisted. Prepaid cards bought with cash sever link to identity. Package tracking links purchases to addresses.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Cash withdrawal strategy
# Build reserve over months (avoid large single withdrawals)
# Withdraw $200-300 per week during normal banking
# Store in fireproof safe at home
# Track total with encrypted ledger

# Encrypted expense ledger
cat > ~/.ledger/expenses.txt << 'EOF'
2024-01-15 | Cash withdrawal | $300
2024-01-20 | Privacy tool purchase | $50
EOF

gpg --encrypt --recipient your@email.com ~/.ledger/expenses.txt
shred -vfz ~/.ledger/expenses.txt

# View ledger
gpg --decrypt ~/.ledger/expenses.txt.gpg

# Monero setup (privacy-by-default cryptocurrency)
# Download: https://www.getmonero.org/downloads/

# Verify download
# Import Monero signing key
gpg --keyserver hkps://keys.openpgp.org --recv-keys 0x1E9E4FA7F19A2E5A

# Verify signature
gpg --verify monero-linux-x64-v0.18.3.1.tar.bz2.asc monero-linux-x64-v0.18.3.1.tar.bz2

# Extract and run
tar xvf monero-linux-x64-v0.18.3.1.tar.bz2
cd monero-x86_64-linux-gnu-v0.18.3.1
./monerod  # Start daemon (syncs blockchain, takes time)

# Create wallet (in separate terminal)
./monero-wallet-cli --generate-new-wallet ~/Monero/Wallets/primary

# Backup wallet seed (25 words) - CRITICAL
# Write on paper, store in safe
# If computer compromised/lost, seed restores funds

# Receive XMR
# Share your address (public, safe to share)
# Funds appear after 10 confirmations (~20 minutes)

# Send XMR
transfer ADDRESS AMOUNT
# Transaction is private: sender, receiver, amount all hidden

# Bitcoin privacy (NOT recommended, use Monero instead)
# If forced to use BTC, improve privacy with:

# 1. Use full node (don't trust SPV/web wallets)
sudo apt install bitcoind
bitcoind -daemon

# 2. Use different address per transaction
bitcoin-cli getnewaddress

# 3. Use Tor for node connections
bitcoind -proxy=127.0.0.1:9050

# 4. Coinjoin with Wasabi Wallet or Samourai
# Download Wasabi: https://wasabiwallet.io/
# Coinjoin mixes your BTC with others (improved privacy)

# Prepaid cards with cash
# 1. Buy Visa/Mastercard gift cards at grocery store with cash
# 2. No ID required for cards under $500 (in most jurisdictions)
# 3. Register online with fake name/address (use Tor)
# 4. Use for online purchases
# 5. Discard after use (don't reuse)

# Privacy.com virtual cards (US only, requires bank link)
# Creates disposable card numbers
# Hides real card from merchants
# BUT: Privacy.com knows all transactions

# Anonymous shipping with package lockers
# Amazon Locker: no signature, no ID
# UPS Access Point: pick up without home address
# General Delivery (USPS): 
# Address to: Your Name, General Delivery, City, State, ZIP
# Pick up at post office with ID
# Use pseudonym if legal in jurisdiction

# Avoid Venmo/PayPal/CashApp public feeds
# These leak social graphs and purchase descriptions
# Set all transactions to Private in settings
# Better: Don't use these for sensitive transactions

# Track patterns to avoid anomalies
# Withdraw cash regularly (every week)
# Don't suddenly withdraw $5k (triggers suspicion)
# Maintain normal transaction patterns</code></pre>

        <h2>13. Software Trust</h2>
        <p>
            Authenticity checks are your guardrail against tampered updates and forged binaries. Do not install software you cannot verify.
        </p>
        
        <p><strong>Why This Matters:</strong> Supply chain attacks compromise software at its source: malicious code in updates, backdoored dependencies, or tampered binaries. The SolarWinds breach (2020) affected 18,000 organizations via trojanized update. npm and PyPI have hosted thousands of malicious packages. Unsigned software could be modified in transit (MITM attack) or on compromised mirrors. Without verification, you're trusting whoever controls the download server. Cryptographic signatures prove software comes from legitimate developer and hasn't been modified.</p>
        
        <h3>Checksums and Signatures</h3>
        <ol>
            <li>Import the developer key: <code>gpg --import developer_key.asc</code>.</li>
            <li>Download both the asset and its signature or checksum file.</li>
            <li>Verify: <code>gpg --verify app.iso.sig app.iso</code> or <code>sha256sum --check app.iso.sha256</code>.</li>
        </ol>
        <p>
            A good signature proves provenance. A bad signature means delete immediately, capture the download URL for forensics, and alert the maintainer.
        </p>
        
        <p><strong>Security Impact:</strong> GPG signatures use public-key cryptography: developer signs with private key, you verify with public key. If signature matches, file is authentic and unmodified. SHA256 checksums verify integrity (file not corrupted) but don't prove authenticity (attacker can publish matching checksum). Always prefer GPG signatures over checksums alone. Import keys from multiple sources (website, keyserver, GitHub) to detect impersonation.</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Verify software signatures (example: Tor Browser)

# 1. Import signing key
gpg --auto-key-locate nodefault,wkd --locate-keys torbrowser@torproject.org

# Alternative: import from keyserver
gpg --keyserver keys.openpgp.org --recv-keys 0x4E2C6E8793298290

# 2. Download software and signature
wget https://dist.torproject.org/torbrowser/13.0/tor-browser-linux-x86_64-13.0.tar.xz
wget https://dist.torproject.org/torbrowser/13.0/tor-browser-linux-x86_64-13.0.tar.xz.asc

# 3. Verify signature
gpg --verify tor-browser-linux-x86_64-13.0.tar.xz.asc tor-browser-linux-x86_64-13.0.tar.xz

# Should show:
# Good signature from "Tor Browser Developers (signing key) <torbrowser@torproject.org>"
# WARNING: This key is not certified with a trusted signature!
# (Warning is normal unless you've signed the key yourself)

# 4. Verify key fingerprint matches published fingerprint
gpg --fingerprint torbrowser@torproject.org
# Compare to: https://support.torproject.org/tbb/how-to-verify-signature/

# Checksum verification (example: Ubuntu ISO)
# 1. Download ISO and checksum file
wget https://releases.ubuntu.com/22.04/ubuntu-22.04.3-desktop-amd64.iso
wget https://releases.ubuntu.com/22.04/SHA256SUMS
wget https://releases.ubuntu.com/22.04/SHA256SUMS.gpg

# 2. Verify checksum file signature
gpg --keyserver keyserver.ubuntu.com --recv-keys 0x843938DF228D22F7B3742BC0D94AA3F0EFE21092
gpg --verify SHA256SUMS.gpg SHA256SUMS

# 3. Verify ISO checksum
sha256sum --ignore-missing -c SHA256SUMS

# Should show:
# ubuntu-22.04.3-desktop-amd64.iso: OK

# Verify Docker images with cosign
# Install cosign
wget https://github.com/sigstore/cosign/releases/download/v2.2.0/cosign-linux-amd64
chmod +x cosign-linux-amd64
sudo mv cosign-linux-amd64 /usr/local/bin/cosign

# Verify signed container image
cosign verify --key cosign.pub ghcr.io/sigstore/cosign:latest

# Package manager verification (apt)
# GPG verification is automatic, but verify keys are trusted
apt-key list

# Verify repository key fingerprint
apt-key fingerprint

# Add new repository safely
wget -qO - https://repository.example.com/key.gpg | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/example.gpg
# Verify fingerprint before trusting

# Python package verification (pip with hash checking)
# Create requirements.txt with hashes
pip hash Flask==2.3.0
# Generates: Flask==2.3.0 --hash=sha256:abc123...

# Install with hash verification (fails if hash doesn't match)
pip install --require-hashes -r requirements.txt

# Node.js package verification (npm)
# Check package integrity
npm audit
npm audit fix

# Verify package lock hashes
npm ci  # Uses exact versions from package-lock.json</code></pre>
        
        <h3>Supply Chain Attacks</h3>
        <ul>
            <li>Delay non-critical updates so the community can surface compromise indicators. Subscribe to project mailing lists for security advisories.</li>
            <li>Favor projects with reproducible builds so you can confirm source and binary parity. Verify container images with <code>cosign verify</code> or <code>sigstore</code> tooling.</li>
            <li>Pin dependencies with checksums in your build systems. Monitor SBOM outputs for unexpected libraries.</li>
        </ul>
        
        <p><strong>Security Impact:</strong> Zero-day supply chain attacks are undetectable at release. Waiting 24-48 hours allows community to review code, spot anomalies, and report issues. Reproducible builds mean multiple people compile from source and compare binaries: if binaries match, code hasn't been tampered with. Dependency pinning prevents automatic updates that could introduce malicious code. Software Bill of Materials (SBOM) lists all dependencies: reviewing it spots unexpected libraries (typosquatting, malicious packages).</p>
        
        <p><strong>Practical Defense:</strong></p>
        <pre data-lang="bash"><code class="language-bash"># Delay updates for 24-48 hours
# Subscribe to security mailing lists
# Examples:
# - oss-security@lists.openwall.com
# - fulldisclosure@seclists.org
# - Project-specific lists (Debian security, etc.)

# Check recent commits before updating
git log --since="24 hours ago" --oneline

# Review changes in dependencies
pip list --outdated
npm outdated

# Pin exact versions in requirements (Python)
pip freeze > requirements.txt
# Generates: Flask==2.3.0 (exact version, not Flask>=2.3.0)

# Pin exact versions (Node.js)
npm install --save-exact package@1.2.3

# Lock files prevent supply chain attacks
# package-lock.json (npm), Pipfile.lock (Python), Cargo.lock (Rust)
# Commit lock files to version control

# Reproducible builds verification (Debian example)
# Install debsums
sudo apt install debsums

# Verify installed packages match repository
debsums -a

# Check if package is reproducible
# Visit: https://reproducible-builds.org/
# Debian: https://tests.reproducible-builds.org/debian/

# SBOM generation (software bill of materials)
# For Python projects
pip install cyclonedx-bom
cyclonedx-py -o sbom.json

# Review SBOM for unexpected dependencies
jq '.components[].name' sbom.json | sort | uniq

# For Node.js
npm sbom

# For containers
docker sbom IMAGE_NAME

# Audit dependencies for known vulnerabilities
# Python
pip install safety
safety check

# Node.js
npm audit

# Rust
cargo audit

# Monitor for compromised packages
# Use Snyk, GitHub Dependabot, or GitLab dependency scanning
# These alert on known malicious packages

# Verify package provenance (npm)
npm view package-name

# Check package maintainer reputation
# Look for:
# - Account age (older = more trusted)
# - Number of dependents (popular = vetted)
# - Update frequency (abandoned packages are risky)
# - GitHub stars/contributors

# Build from source when possible (high-security environments)
git clone https://github.com/project/repo.git
cd repo
git verify-tag v1.2.3  # Verify release tag signature
git checkout v1.2.3
./configure && make && sudo make install</code></pre>

        <h2>Closing Practice</h2>
        <p>
            Privacy is a discipline, not a product. Document your procedures, audit yourself, and train the people around you. Encrypt everything, scrub everything, log everything, and keep your habits sharper than your adversaries. Schedule drills, review logs, and keep refining the system so complacency never sets in.
        </p>
        
        <p><strong>Final Thoughts:</strong> Operational security is a continuous process of threat modeling, implementing controls, and adapting to new attacks. No single tool provides complete protection: security comes from layered defenses (defense in depth). Your weakest link determines your security level: the strongest encryption is useless if you reuse passwords. The most sophisticated anonymity network fails if you leak identifying information through writing style or metadata. Train regularly, test your procedures, and maintain discipline. Assume breach, plan recovery, and never stop learning.</p>
    </article>

<div class="flex justify-between mt-12 pt-6 border-t border-shell-border">
    <a href="#/posts/1.OpSec_101/part1.html" class="text-shell-accent hover:underline">← Part 1: Understanding the Basics</a>
    <a href="#/posts/1.OpSec_101/part3.html" class="text-shell-accent hover:underline">Part 3: OpSec Pre-Flight Checklist →</a>
</div>
</body>
</html>
